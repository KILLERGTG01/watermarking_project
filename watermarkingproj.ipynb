{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dlUOTit0DVq",
        "outputId": "aba48180-9eec-4219-b8e9-909b4af23121"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from functools import partial\n",
        "import kagglehub\n",
        "import shutil\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "\n",
        "# Define the CNN model with batch normalization and more efficient architecture\n",
        "class WatermarkCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WatermarkCNN, self).__init__()\n",
        "        # Encoder with batch normalization for faster convergence and training stability\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),  # inplace operations save memory\n",
        "            nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        # Decoder with batch normalization\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Move model to GPU if available\n",
        "        self.to(device)\n",
        "\n",
        "    def encode(self, image, watermark):\n",
        "        # Optimize watermark preparation\n",
        "        watermark = watermark.resize((image.shape[3], image.shape[2]))\n",
        "        watermark_tensor = transforms.ToTensor()(watermark).unsqueeze(0).to(device)\n",
        "\n",
        "        # Handle batch processing\n",
        "        if watermark_tensor.shape[0] != image.shape[0]:\n",
        "            watermark_tensor = watermark_tensor.repeat(image.shape[0], 1, 1, 1)\n",
        "\n",
        "        encoded_image = self.encoder(image + watermark_tensor)\n",
        "        return encoded_image\n",
        "\n",
        "    def decode(self, watermarked_image):\n",
        "        decoded_watermark = self.decoder(watermarked_image)\n",
        "        return decoded_watermark\n",
        "\n",
        "# Cache for the model instance to avoid reloading\n",
        "model_cache = None\n",
        "\n",
        "def get_model():\n",
        "    global model_cache\n",
        "    if model_cache is None:\n",
        "        model_cache = WatermarkCNN()\n",
        "        # Here you would load pre-trained weights if available\n",
        "        # model_cache.load_state_dict(torch.load('watermark_model.pth'))\n",
        "    return model_cache\n",
        "\n",
        "# Optimized detection with batching support\n",
        "def detect_watermark(image_path):\n",
        "    model = get_model()\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    transform = transforms.ToTensor()\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        watermark = model.decode(image_tensor)\n",
        "        has_watermark = torch.mean(watermark) > 0.05  # Threshold for watermark presence\n",
        "\n",
        "    return has_watermark.item(), image_tensor\n",
        "\n",
        "# Optimized watermark removal\n",
        "def remove_watermark(image_tensor):\n",
        "    model = get_model()\n",
        "    with torch.no_grad():\n",
        "        watermark = model.decode(image_tensor)\n",
        "        cleaned_image = image_tensor - watermark\n",
        "    return cleaned_image\n",
        "\n",
        "# Optimized watermark addition\n",
        "def add_watermark(image_tensor, watermark):\n",
        "    model = get_model()\n",
        "    return model.encode(image_tensor, watermark)\n",
        "\n",
        "# Process single image\n",
        "def process_single_image(filename, input_dir, watermark_img, output_unwatermarked, output_watermarked):\n",
        "    img_path = os.path.join(input_dir, filename)\n",
        "\n",
        "    try:\n",
        "        has_watermark, image_tensor = detect_watermark(img_path)\n",
        "\n",
        "        if has_watermark:\n",
        "            cleaned_image = remove_watermark(image_tensor)\n",
        "            cleaned_image_pil = transforms.ToPILImage()(cleaned_image.squeeze(0).cpu())\n",
        "            output_path = os.path.join(output_unwatermarked, filename)\n",
        "            cleaned_image_pil.save(output_path)\n",
        "            return f\"Removed watermark from: {filename}\"\n",
        "        else:\n",
        "            watermarked_image = add_watermark(image_tensor, watermark_img)\n",
        "            watermarked_image_pil = transforms.ToPILImage()(watermarked_image.squeeze(0).cpu())\n",
        "            output_path = os.path.join(output_watermarked, filename)\n",
        "            watermarked_image_pil.save(output_path)\n",
        "            return f\"Added watermark to: {filename}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error processing {filename}: {str(e)}\"\n",
        "\n",
        "# Main processing function with parallel execution\n",
        "def process_images(input_dir, watermark_path, output_unwatermarked, output_watermarked, num_workers=None):\n",
        "    # Create output directories if they don't exist\n",
        "    os.makedirs(output_unwatermarked, exist_ok=True)\n",
        "    os.makedirs(output_watermarked, exist_ok=True)\n",
        "\n",
        "    # Load watermark once\n",
        "    watermark_img = Image.open(watermark_path).convert(\"RGB\")\n",
        "\n",
        "    # Get list of image files\n",
        "    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
        "\n",
        "    # Process images in parallel\n",
        "    process_func = partial(\n",
        "        process_single_image,\n",
        "        input_dir=input_dir,\n",
        "        watermark_img=watermark_img,\n",
        "        output_unwatermarked=output_unwatermarked,\n",
        "        output_watermarked=output_watermarked\n",
        "    )\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
        "        results = list(executor.map(process_func, image_files))\n",
        "\n",
        "    # Print results\n",
        "    for result in results:\n",
        "        print(result)\n",
        "\n",
        "    return len(image_files)\n",
        "\n",
        "# Function to download and prepare Kaggle dataset\n",
        "def download_and_prepare_kaggle_dataset():\n",
        "    print(\"Downloading watermarked/non-watermarked dataset from Kaggle...\")\n",
        "    dataset_path = kagglehub.dataset_download(\"felicepollano/watermarked-not-watermarked-images\")\n",
        "    print(f\"Dataset downloaded to: {dataset_path}\")\n",
        "\n",
        "    # Create input directory for our processing\n",
        "    input_dir = \"input_images\"\n",
        "    os.makedirs(input_dir, exist_ok=True)\n",
        "\n",
        "    # Copy a sample of images from the dataset to our input directory\n",
        "    # The dataset likely has a structure we need to navigate\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "                source_path = os.path.join(root, file)\n",
        "                dest_path = os.path.join(input_dir, file)\n",
        "                shutil.copy2(source_path, dest_path)\n",
        "                print(f\"Copied {file} to input directory\")\n",
        "\n",
        "    return input_dir\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Download and prepare the Kaggle dataset\n",
        "    input_dir = download_and_prepare_kaggle_dataset()\n",
        "\n",
        "    # Paths and directories\n",
        "    watermark_path = \"watermark.png\"  # We'll need to create or get a watermark image\n",
        "    output_unwatermarked = \"output/unwatermarked\"\n",
        "    output_watermarked = \"output/watermarked\"\n",
        "\n",
        "    # Check if watermark image exists, if not create a simple one\n",
        "    if not os.path.exists(watermark_path):\n",
        "        print(\"Creating a sample watermark image...\")\n",
        "        from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "        # Create a blank image with transparent background\n",
        "        watermark = Image.new('RGBA', (200, 100), (255, 255, 255, 0))\n",
        "        draw = ImageDraw.Draw(watermark)\n",
        "\n",
        "        # Draw text on the image\n",
        "        draw.text((10, 10), \"WATERMARK\", fill=(255, 255, 255, 128))\n",
        "\n",
        "        # Save as PNG to preserve transparency\n",
        "        watermark = watermark.convert(\"RGB\")\n",
        "        watermark.save(watermark_path)\n",
        "        print(f\"Sample watermark created at {watermark_path}\")\n",
        "\n",
        "    # Determine optimal number of workers based on CPU cores\n",
        "    num_workers = min(os.cpu_count(), 8)  # Cap at 8 workers to avoid excessive resource usage\n",
        "\n",
        "    # Process the images\n",
        "    num_processed = process_images(\n",
        "        input_dir,\n",
        "        watermark_path,\n",
        "        output_unwatermarked,\n",
        "        output_watermarked,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    print(f\"Processing complete! Processed {num_processed} images using {num_workers} workers.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from functools import partial\n",
        "import kagglehub\n",
        "import shutil\n",
        "import argparse\n",
        "\n",
        "# Use CUDA if available, then MPS, then fallback to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \n",
        "                    \"mps\" if torch.backends.mps.is_available() else \n",
        "                    \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the CNN model with batch normalization and more efficient architecture\n",
        "class WatermarkCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WatermarkCNN, self).__init__()\n",
        "        # Encoder with batch normalization for faster convergence and training stability\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),  # inplace operations save memory\n",
        "            nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        # Decoder with batch normalization\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Move model to GPU if available\n",
        "        self.to(device)\n",
        "\n",
        "    def encode(self, image, watermark):\n",
        "        # Optimize watermark preparation\n",
        "        watermark = watermark.resize((image.shape[3], image.shape[2]))\n",
        "        watermark_tensor = transforms.ToTensor()(watermark).unsqueeze(0).to(device)\n",
        "\n",
        "        # Handle batch processing\n",
        "        if watermark_tensor.shape[0] != image.shape[0]:\n",
        "            watermark_tensor = watermark_tensor.repeat(image.shape[0], 1, 1, 1)\n",
        "\n",
        "        encoded_image = self.encoder(image + watermark_tensor)\n",
        "        return encoded_image\n",
        "\n",
        "    def decode(self, watermarked_image):\n",
        "        decoded_watermark = self.decoder(watermarked_image)\n",
        "        return decoded_watermark\n",
        "\n",
        "# Cache for the model instance to avoid reloading\n",
        "model_cache = None\n",
        "\n",
        "def get_model():\n",
        "    global model_cache\n",
        "    if model_cache is None:\n",
        "        model_cache = WatermarkCNN()\n",
        "        # Here you would load pre-trained weights if available\n",
        "        # model_cache.load_state_dict(torch.load('watermark_model.pth', map_location=device))\n",
        "    return model_cache\n",
        "\n",
        "# Optimized detection with batching support\n",
        "def detect_watermark(image_path):\n",
        "    model = get_model()\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    transform = transforms.ToTensor()\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        watermark = model.decode(image_tensor)\n",
        "        has_watermark = torch.mean(watermark) > 0.05  # Threshold for watermark presence\n",
        "\n",
        "    return has_watermark.item(), image_tensor\n",
        "\n",
        "# Optimized watermark removal\n",
        "def remove_watermark(image_tensor):\n",
        "    model = get_model()\n",
        "    with torch.no_grad():\n",
        "        watermark = model.decode(image_tensor)\n",
        "        cleaned_image = image_tensor - watermark\n",
        "    return cleaned_image\n",
        "\n",
        "# Optimized watermark addition\n",
        "def add_watermark(image_tensor, watermark):\n",
        "    model = get_model()\n",
        "    return model.encode(image_tensor, watermark)\n",
        "\n",
        "# Process single image\n",
        "def process_single_image(filename, input_dir, watermark_img, output_unwatermarked, output_watermarked):\n",
        "    img_path = os.path.join(input_dir, filename)\n",
        "\n",
        "    try:\n",
        "        has_watermark, image_tensor = detect_watermark(img_path)\n",
        "\n",
        "        if has_watermark:\n",
        "            cleaned_image = remove_watermark(image_tensor)\n",
        "            cleaned_image_pil = transforms.ToPILImage()(cleaned_image.squeeze(0).cpu())\n",
        "            output_path = os.path.join(output_unwatermarked, filename)\n",
        "            cleaned_image_pil.save(output_path)\n",
        "            return f\"Removed watermark from: {filename}\"\n",
        "        else:\n",
        "            watermarked_image = add_watermark(image_tensor, watermark_img)\n",
        "            watermarked_image_pil = transforms.ToPILImage()(watermarked_image.squeeze(0).cpu())\n",
        "            output_path = os.path.join(output_watermarked, filename)\n",
        "            watermarked_image_pil.save(output_path)\n",
        "            return f\"Added watermark to: {filename}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error processing {filename}: {str(e)}\"\n",
        "\n",
        "# Main processing function with parallel execution\n",
        "def process_images(input_dir, watermark_path, output_unwatermarked, output_watermarked, num_workers=None):\n",
        "    # Create output directories if they don't exist\n",
        "    os.makedirs(output_unwatermarked, exist_ok=True)\n",
        "    os.makedirs(output_watermarked, exist_ok=True)\n",
        "\n",
        "    # Verify watermark exists\n",
        "    if not os.path.exists(watermark_path):\n",
        "        raise FileNotFoundError(f\"Watermark image not found: {watermark_path}\")\n",
        "    \n",
        "    # Load watermark once\n",
        "    try:\n",
        "        watermark_img = Image.open(watermark_path).convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error loading watermark image: {str(e)}\")\n",
        "\n",
        "    # Get list of image files\n",
        "    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
        "    \n",
        "    if not image_files:\n",
        "        print(f\"No image files found in {input_dir}\")\n",
        "        return 0\n",
        "\n",
        "    # Process images in parallel\n",
        "    process_func = partial(\n",
        "        process_single_image,\n",
        "        input_dir=input_dir,\n",
        "        watermark_img=watermark_img,\n",
        "        output_unwatermarked=output_unwatermarked,\n",
        "        output_watermarked=output_watermarked\n",
        "    )\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
        "        results = list(executor.map(process_func, image_files))\n",
        "\n",
        "    # Print results\n",
        "    for result in results:\n",
        "        print(result)\n",
        "\n",
        "    return len(image_files)\n",
        "\n",
        "# Function to download and prepare Kaggle dataset\n",
        "def download_and_prepare_kaggle_dataset():\n",
        "    print(\"Downloading watermarked/non-watermarked dataset from Kaggle...\")\n",
        "    dataset_path = kagglehub.dataset_download(\"felicepollano/watermarked-not-watermarked-images\")\n",
        "    print(f\"Dataset downloaded to: {dataset_path}\")\n",
        "\n",
        "    # Create input directory for our processing\n",
        "    input_dir = \"input_images\"\n",
        "    os.makedirs(input_dir, exist_ok=True)\n",
        "\n",
        "    # Copy a sample of images from the dataset to our input directory\n",
        "    # The dataset likely has a structure we need to navigate\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "                source_path = os.path.join(root, file)\n",
        "                dest_path = os.path.join(input_dir, file)\n",
        "                shutil.copy2(source_path, dest_path)\n",
        "                print(f\"Copied {file} to input directory\")\n",
        "\n",
        "    return input_dir\n",
        "\n",
        "def parse_arguments():\n",
        "    parser = argparse.ArgumentParser(description='Watermark Detection and Processing Tool')\n",
        "    parser.add_argument('--watermark', type=str, required=True, \n",
        "                        help='Path to the watermark image (required)')\n",
        "    parser.add_argument('--input-dir', type=str, default=None,\n",
        "                        help='Directory containing input images (if not specified, will download from Kaggle)')\n",
        "    parser.add_argument('--output-unwatermarked', type=str, default='output/unwatermarked',\n",
        "                        help='Directory for cleaned images (default: output/unwatermarked)')\n",
        "    parser.add_argument('--output-watermarked', type=str, default='output/watermarked',\n",
        "                        help='Directory for watermarked images (default: output/watermarked)')\n",
        "    parser.add_argument('--workers', type=int, default=None,\n",
        "                        help='Number of worker threads (default: auto)')\n",
        "    \n",
        "    return parser.parse_args()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Parse command-line arguments\n",
        "    args = parse_arguments()\n",
        "    \n",
        "    # Get input directory\n",
        "    input_dir = args.input_dir\n",
        "    if input_dir is None:\n",
        "        # Download and prepare the Kaggle dataset if no input directory provided\n",
        "        input_dir = download_and_prepare_kaggle_dataset()\n",
        "    \n",
        "    # Ensure the input directory exists\n",
        "    if not os.path.exists(input_dir):\n",
        "        raise FileNotFoundError(f\"Input directory not found: {input_dir}\")\n",
        "    \n",
        "    # Verify watermark path\n",
        "    watermark_path = args.watermark\n",
        "    if not os.path.exists(watermark_path):\n",
        "        raise FileNotFoundError(f\"Watermark image not found: {watermark_path}\")\n",
        "    \n",
        "    output_unwatermarked = args.output_unwatermarked\n",
        "    output_watermarked = args.output_watermarked\n",
        "    \n",
        "    # Determine optimal number of workers if not specified\n",
        "    num_workers = args.workers\n",
        "    if num_workers is None:\n",
        "        num_workers = min(os.cpu_count(), 8)  # Cap at 8 workers to avoid excessive resource usage\n",
        "    \n",
        "    print(f\"Processing with the following settings:\")\n",
        "    print(f\"- Input directory: {input_dir}\")\n",
        "    print(f\"- Watermark image: {watermark_path}\")\n",
        "    print(f\"- Output directory (unwatermarked): {output_unwatermarked}\")\n",
        "    print(f\"- Output directory (watermarked): {output_watermarked}\")\n",
        "    print(f\"- Workers: {num_workers}\")\n",
        "    print(f\"- Device: {device}\")\n",
        "    \n",
        "    try:\n",
        "        # Process the images\n",
        "        num_processed = process_images(\n",
        "            input_dir,\n",
        "            watermark_path,\n",
        "            output_unwatermarked,\n",
        "            output_watermarked,\n",
        "            num_workers=num_workers\n",
        "        )\n",
        "        \n",
        "        print(f\"Processing complete! Processed {num_processed} images using {num_workers} workers.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during processing: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
