{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n",
            "No valid watermark path provided. Will use a blank watermark during training.\n",
            "Found 12477 clean images and 12510 watermarked images\n",
            "Found 3289 clean images and 3299 watermarked images\n",
            "Training model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    from multiprocessing.spawn import spawn_main; \u001b[31mspawn_main\u001b[0m\u001b[1;31m(tracker_fd=79, pipe_handle=93)\u001b[0m\n",
            "                                                  \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m122\u001b[0m, in \u001b[35mspawn_main\u001b[0m\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \u001b[35m\"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m132\u001b[0m, in \u001b[35m_main\u001b[0m\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "\u001b[1;35mAttributeError\u001b[0m: \u001b[35mCan't get attribute 'WatermarkDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from functools import partial\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"mps\" if torch.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the HiDDeN-based model\n",
        "class HiDDeNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HiDDeNModel, self).__init__()\n",
        "        \n",
        "        # Watermark classifier (detects if image has watermark)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "        self.classifier_fc = nn.Linear(256, 1)\n",
        "        \n",
        "        # Encoder (for adding watermark)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(6, 64, kernel_size=3, padding=1),  # 3 (image) + 3 (watermark)\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
        "            nn.Tanh()  # Tanh to keep values in [-1, 1] range\n",
        "        )\n",
        "\n",
        "        # Decoder (for extracting/removing watermark)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Move model to GPU if available\n",
        "        self.to(device)\n",
        "\n",
        "    def classify(self, image):\n",
        "        \"\"\"Determine if image has watermark\"\"\"\n",
        "        features = self.classifier(image)\n",
        "        features = features.view(features.size(0), -1)\n",
        "        return torch.sigmoid(self.classifier_fc(features))\n",
        "\n",
        "    def encode(self, image, watermark):\n",
        "        \"\"\"Add watermark to image\"\"\"\n",
        "        # Ensure watermark has same dimensions as image\n",
        "        if watermark.shape[2:] != image.shape[2:]:\n",
        "            watermark = F.interpolate(watermark, size=image.shape[2:], mode='bilinear', align_corners=False)\n",
        "        \n",
        "        # Concatenate image and watermark along channel dimension\n",
        "        combined = torch.cat([image, watermark], dim=1)\n",
        "        encoded_image = image + self.encoder(combined)\n",
        "        \n",
        "        # Ensure pixel values stay in valid range\n",
        "        encoded_image = torch.clamp(encoded_image, -1, 1)\n",
        "        return encoded_image\n",
        "\n",
        "    def decode(self, watermarked_image):\n",
        "        \"\"\"Extract watermark from image\"\"\"\n",
        "        extracted_watermark = self.decoder(watermarked_image)\n",
        "        return extracted_watermark\n",
        "    \n",
        "    def remove_watermark(self, watermarked_image):\n",
        "        \"\"\"Remove watermark from image\"\"\"\n",
        "        extracted_watermark = self.decode(watermarked_image)\n",
        "        clean_image = watermarked_image - extracted_watermark\n",
        "        clean_image = torch.clamp(clean_image, -1, 1)\n",
        "        return clean_image\n",
        "\n",
        "# Custom dataset for watermarked and non-watermarked images\n",
        "class WatermarkDataset(Dataset):\n",
        "    def __init__(self, clean_dir, watermarked_dir=None, watermark_path=None, transform=None, is_train=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            clean_dir (string): Directory with non-watermarked/clean images.\n",
        "            watermarked_dir (string): Directory with watermarked images.\n",
        "            watermark_path (string): Path to watermark image to use for training.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "            is_train (bool): Whether this is training or validation set.\n",
        "        \"\"\"\n",
        "        self.clean_dir = clean_dir\n",
        "        self.watermarked_dir = watermarked_dir\n",
        "        self.watermark_path = watermark_path\n",
        "        self.transform = transform\n",
        "        self.is_train = is_train\n",
        "        self.watermark_tensor = None\n",
        "        \n",
        "        # Get all clean image files\n",
        "        self.clean_image_files = []\n",
        "        if os.path.exists(clean_dir):\n",
        "            self.clean_image_files = [f for f in os.listdir(clean_dir)\n",
        "                        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
        "        \n",
        "        # Get all watermarked image files if directory is provided\n",
        "        self.watermarked_image_files = []\n",
        "        if watermarked_dir and os.path.exists(watermarked_dir):\n",
        "            self.watermarked_image_files = [f for f in os.listdir(watermarked_dir)\n",
        "                            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
        "        \n",
        "        # Load watermark if provided\n",
        "        if watermark_path and os.path.exists(watermark_path):\n",
        "            watermark_img = Image.open(watermark_path).convert('RGB')\n",
        "            if transform:\n",
        "                self.watermark_tensor = transform(watermark_img)\n",
        "            print(f\"Using watermark from: {watermark_path}\")\n",
        "        \n",
        "        print(f\"Found {len(self.clean_image_files)} clean images and {len(self.watermarked_image_files)} watermarked images\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        if self.is_train:\n",
        "            # For training, use both clean and watermarked images\n",
        "            return len(self.clean_image_files) + len(self.watermarked_image_files)\n",
        "        else:\n",
        "            # For validation, use all available images\n",
        "            return len(self.clean_image_files) + len(self.watermarked_image_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Determine if we're loading a clean or watermarked image\n",
        "        if idx >= len(self.clean_image_files):\n",
        "            # This is a watermarked image\n",
        "            if len(self.watermarked_image_files) == 0:\n",
        "                # No watermarked images available, wrap around to clean images\n",
        "                clean_idx = idx % len(self.clean_image_files)\n",
        "                img_name = os.path.join(self.clean_dir, self.clean_image_files[clean_idx])\n",
        "                image = Image.open(img_name).convert('RGB')\n",
        "                \n",
        "                if self.transform:\n",
        "                    image = self.transform(image)\n",
        "                \n",
        "                # Use a blank watermark if none provided\n",
        "                if self.watermark_tensor is None:\n",
        "                    watermark = torch.zeros_like(image)\n",
        "                else:\n",
        "                    watermark = self.watermark_tensor\n",
        "                \n",
        "                return {\n",
        "                    'image': image,\n",
        "                    'watermark': watermark,\n",
        "                    'has_watermark': torch.tensor([0.0], dtype=torch.float32)  # Treat as non-watermarked\n",
        "                }\n",
        "            else:\n",
        "                # Load actual watermarked image\n",
        "                watermarked_idx = idx - len(self.clean_image_files)\n",
        "                watermarked_idx = watermarked_idx % len(self.watermarked_image_files)  # Handle overflow\n",
        "                img_name = os.path.join(self.watermarked_dir, self.watermarked_image_files[watermarked_idx])\n",
        "                image = Image.open(img_name).convert('RGB')\n",
        "                \n",
        "                if self.transform:\n",
        "                    image = self.transform(image)\n",
        "                \n",
        "                # Use a blank watermark if none provided\n",
        "                if self.watermark_tensor is None:\n",
        "                    watermark = torch.zeros_like(image)\n",
        "                else:\n",
        "                    watermark = self.watermark_tensor\n",
        "                \n",
        "                return {\n",
        "                    'image': image,\n",
        "                    'watermark': watermark,\n",
        "                    'has_watermark': torch.tensor([1.0], dtype=torch.float32)\n",
        "                }\n",
        "        else:\n",
        "            # This is a clean/non-watermarked image\n",
        "            img_name = os.path.join(self.clean_dir, self.clean_image_files[idx])\n",
        "            image = Image.open(img_name).convert('RGB')\n",
        "            \n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            \n",
        "            # Use a blank watermark if none provided\n",
        "            if self.watermark_tensor is None:\n",
        "                watermark = torch.zeros_like(image)\n",
        "            else:\n",
        "                watermark = self.watermark_tensor\n",
        "            \n",
        "            return {\n",
        "                'image': image,\n",
        "                'watermark': watermark,\n",
        "                'has_watermark': torch.tensor([0.0], dtype=torch.float32)\n",
        "            }\n",
        "\n",
        "# Helper functions for training\n",
        "def train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.001):\n",
        "    \"\"\"Train the HiDDeN model\"\"\"\n",
        "    # Optimizers\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    \n",
        "    # Loss functions\n",
        "    classifier_criterion = nn.BCELoss()\n",
        "    reconstruction_criterion = nn.MSELoss()\n",
        "    \n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_classifier_loss = 0.0\n",
        "        train_encoder_loss = 0.0\n",
        "        train_decoder_loss = 0.0\n",
        "        train_removal_loss = 0.0\n",
        "        \n",
        "        for batch in train_loader:\n",
        "            images = batch['image'].to(device)\n",
        "            watermarks = batch['watermark'].to(device)\n",
        "            has_watermark = batch['has_watermark'].to(device)\n",
        "            \n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass - classification\n",
        "            watermark_pred = model.classify(images)\n",
        "            \n",
        "            # Classification loss\n",
        "            classifier_loss = classifier_criterion(watermark_pred, has_watermark)\n",
        "            \n",
        "            # Split batch into watermarked and clean images based on has_watermark\n",
        "            watermarked_indices = has_watermark.squeeze() > 0.5\n",
        "            clean_indices = ~watermarked_indices\n",
        "            \n",
        "            # Process both parts of the batch\n",
        "            total_loss = classifier_loss  # Start with classification loss\n",
        "            \n",
        "            # If we have watermarked images, train the decoder/removal\n",
        "            if watermarked_indices.sum() > 0:\n",
        "                watermarked_images = images[watermarked_indices]\n",
        "                \n",
        "                # Forward pass - removal (should get back clean image)\n",
        "                clean_recovered = model.remove_watermark(watermarked_images)\n",
        "                \n",
        "                # Since we don't have ground truth clean versions of these images,\n",
        "                # we can use a smoothness constraint\n",
        "                removal_loss = torch.mean(torch.abs(\n",
        "                    clean_recovered[:, :, 1:, :] - clean_recovered[:, :, :-1, :]\n",
        "                )) + torch.mean(torch.abs(\n",
        "                    clean_recovered[:, :, :, 1:] - clean_recovered[:, :, :, :-1]\n",
        "                ))\n",
        "                \n",
        "                # Extract watermark\n",
        "                decoded_watermarks = model.decode(watermarked_images)\n",
        "                \n",
        "                # We want the decoded watermark to be non-zero\n",
        "                decoder_loss = torch.mean((decoded_watermarks.mean(dim=[2, 3]) - 0.5) ** 2)\n",
        "                \n",
        "                train_removal_loss += removal_loss.item()\n",
        "                train_decoder_loss += decoder_loss.item()\n",
        "                total_loss = total_loss + removal_loss + decoder_loss\n",
        "            \n",
        "            # If we have clean images, train the encoder\n",
        "            if clean_indices.sum() > 0:\n",
        "                clean_images = images[clean_indices]\n",
        "                clean_watermarks = watermarks[clean_indices]\n",
        "                \n",
        "                # Forward pass - encoding\n",
        "                encoded_images = model.encode(clean_images, clean_watermarks)\n",
        "                \n",
        "                # Encoding loss (encoded image should be similar to original)\n",
        "                encoder_loss = reconstruction_criterion(encoded_images, clean_images)\n",
        "                \n",
        "                # The encoded image should be classified as watermarked\n",
        "                encoded_pred = model.classify(encoded_images)\n",
        "                has_watermark_encoded = torch.ones_like(encoded_pred)\n",
        "                encoder_classify_loss = classifier_criterion(encoded_pred, has_watermark_encoded)\n",
        "                \n",
        "                # Forward pass - decoding (should recover watermark from encoded image)\n",
        "                decoded_watermarks = model.decode(encoded_images)\n",
        "                decoder_recovery_loss = reconstruction_criterion(decoded_watermarks, clean_watermarks)\n",
        "                \n",
        "                train_encoder_loss += encoder_loss.item()\n",
        "                train_decoder_loss += decoder_recovery_loss.item()\n",
        "                total_loss = total_loss + encoder_loss + encoder_classify_loss + decoder_recovery_loss\n",
        "            \n",
        "            # Backward pass and optimize\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Track classification loss\n",
        "            train_classifier_loss += classifier_loss.item()\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_classifier_loss = 0.0\n",
        "        val_accuracy = 0.0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                images = batch['image'].to(device)\n",
        "                has_watermark = batch['has_watermark'].to(device)\n",
        "                \n",
        "                # Validation on classification\n",
        "                watermark_pred = model.classify(images)\n",
        "                val_loss = classifier_criterion(watermark_pred, has_watermark)\n",
        "                \n",
        "                # Calculate accuracy\n",
        "                predicted = (watermark_pred > 0.5).float()\n",
        "                val_accuracy += (predicted == has_watermark).float().mean().item()\n",
        "                \n",
        "                val_classifier_loss += val_loss.item()\n",
        "        \n",
        "        # Print metrics\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"Train Classifier Loss: {train_classifier_loss/len(train_loader):.4f}\")\n",
        "        print(f\"Train Encoder Loss: {train_encoder_loss/len(train_loader):.4f}\")\n",
        "        print(f\"Train Decoder Loss: {train_decoder_loss/len(train_loader):.4f}\")\n",
        "        print(f\"Train Removal Loss: {train_removal_loss/len(train_loader):.4f}\")\n",
        "        print(f\"Val Classifier Loss: {val_classifier_loss/len(val_loader):.4f}\")\n",
        "        print(f\"Val Accuracy: {val_accuracy/len(val_loader):.4f}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Process single image\n",
        "def process_single_image(filename, input_dir, watermark_img, output_unwatermarked, output_watermarked, model):\n",
        "    img_path = os.path.join(input_dir, filename)\n",
        "\n",
        "    try:\n",
        "        # Load and preprocess image\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        \n",
        "        # Preserve original image dimensions for later\n",
        "        original_width, original_height = image.size\n",
        "        \n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ])\n",
        "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "        \n",
        "        # Prepare watermark\n",
        "        watermark = watermark_img.resize((256, 256))\n",
        "        watermark_tensor = transform(watermark).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Detect if image has watermark\n",
        "            watermark_prob = model.classify(image_tensor)\n",
        "            has_watermark = watermark_prob > 0.5\n",
        "            confidence = abs(watermark_prob.item() - 0.5) * 2  # Scale to 0-1 range\n",
        "\n",
        "            if has_watermark.item():\n",
        "                # Remove watermark\n",
        "                cleaned_image = model.remove_watermark(image_tensor)\n",
        "                \n",
        "                # Convert back to PIL image \n",
        "                cleaned_image = cleaned_image * 0.5 + 0.5  # Denormalize\n",
        "                cleaned_image_pil = transforms.ToPILImage()(cleaned_image.squeeze(0).cpu())\n",
        "                \n",
        "                # Resize back to original dimensions\n",
        "                cleaned_image_pil = cleaned_image_pil.resize((original_width, original_height), Image.LANCZOS)\n",
        "                \n",
        "                # Save the unwatermarked image\n",
        "                output_path = os.path.join(output_unwatermarked, filename)\n",
        "                cleaned_image_pil.save(output_path)\n",
        "                return f\"Removed watermark from: {filename} (confidence: {confidence:.2f})\"\n",
        "            else:\n",
        "                # Add watermark\n",
        "                watermarked_image = model.encode(image_tensor, watermark_tensor)\n",
        "                \n",
        "                # Convert back to PIL image\n",
        "                watermarked_image = watermarked_image * 0.5 + 0.5  # Denormalize\n",
        "                watermarked_image_pil = transforms.ToPILImage()(watermarked_image.squeeze(0).cpu())\n",
        "                \n",
        "                # Resize back to original dimensions\n",
        "                watermarked_image_pil = watermarked_image_pil.resize((original_width, original_height), Image.LANCZOS)\n",
        "                \n",
        "                # Save the watermarked image\n",
        "                output_path = os.path.join(output_watermarked, filename)\n",
        "                watermarked_image_pil.save(output_path)\n",
        "                return f\"Added watermark to: {filename} (confidence: {confidence:.2f})\"\n",
        "    except Exception as e:\n",
        "        return f\"Error processing {filename}: {str(e)}\"\n",
        "\n",
        "# Main processing function with parallel execution\n",
        "def process_images(input_dir, watermark_path, output_unwatermarked, output_watermarked, model, num_workers=None):\n",
        "    # Create output directories if they don't exist\n",
        "    os.makedirs(output_unwatermarked, exist_ok=True)\n",
        "    os.makedirs(output_watermarked, exist_ok=True)\n",
        "\n",
        "    # Load user-provided watermark\n",
        "    try:\n",
        "        watermark_img = Image.open(watermark_path).convert(\"RGB\")\n",
        "        print(f\"Successfully loaded user watermark: {watermark_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading watermark: {str(e)}\")\n",
        "        return 0\n",
        "\n",
        "    # Get list of image files\n",
        "    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
        "    \n",
        "    if len(image_files) == 0:\n",
        "        print(f\"No image files found in {input_dir}\")\n",
        "        return 0\n",
        "\n",
        "    # Process images in parallel\n",
        "    process_func = partial(\n",
        "        process_single_image,\n",
        "        input_dir=input_dir,\n",
        "        watermark_img=watermark_img,\n",
        "        output_unwatermarked=output_unwatermarked,\n",
        "        output_watermarked=output_watermarked,\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
        "        results = list(executor.map(process_func, image_files))\n",
        "\n",
        "    # Print results\n",
        "    for result in results:\n",
        "        print(result)\n",
        "\n",
        "    return len(image_files)\n",
        "\n",
        "def main():\n",
        "    # Define data directories (these should match your provided structure)\n",
        "    train_clean_dir = \"wm-nowm/train/no-watermark\"\n",
        "    train_watermarked_dir = \"wm-nowm/train/watermark\"\n",
        "    val_clean_dir = \"wm-nowm/valid/no-watermark\"\n",
        "    val_watermarked_dir = \"wm-nowm/valid/watermark\" \n",
        "    \n",
        "    # Check if directories exist\n",
        "    for directory in [train_clean_dir, train_watermarked_dir, val_clean_dir, val_watermarked_dir]:\n",
        "        if not os.path.exists(directory):\n",
        "            print(f\"Warning: Directory {directory} does not exist.\")\n",
        "    \n",
        "    # Get watermark path from user for training\n",
        "    watermark_path = input(\"Enter path to watermark image for training (or press Enter to use a blank watermark): \")\n",
        "    if not watermark_path or not os.path.exists(watermark_path):\n",
        "        print(\"No valid watermark path provided. Will use a blank watermark during training.\")\n",
        "        watermark_path = None\n",
        "    \n",
        "    # Prepare data transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = WatermarkDataset(\n",
        "        clean_dir=train_clean_dir,\n",
        "        watermarked_dir=train_watermarked_dir,\n",
        "        watermark_path=watermark_path,\n",
        "        transform=transform,\n",
        "        is_train=True\n",
        "    )\n",
        "    \n",
        "    val_dataset = WatermarkDataset(\n",
        "        clean_dir=val_clean_dir, \n",
        "        watermarked_dir=val_watermarked_dir,\n",
        "        watermark_path=watermark_path,\n",
        "        transform=transform,\n",
        "        is_train=False\n",
        "    )\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
        "    \n",
        "    # Create model\n",
        "    model = HiDDeNModel()\n",
        "    \n",
        "    # Check if model already exists and load it\n",
        "    model_path = \"watermark_model.pth\"\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"Loading existing model from {model_path}\")\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    else:\n",
        "        # Train model\n",
        "        print(\"Training model...\")\n",
        "        model = train_model(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            num_epochs=10,\n",
        "            learning_rate=0.001\n",
        "        )\n",
        "        \n",
        "        # Save model\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f\"Model saved to {model_path}\")\n",
        "    \n",
        "    # Get user inputs for processing\n",
        "    print(\"\\n--- Watermark Processing ---\")\n",
        "    input_dir = input(\"Enter the directory path containing images to process: \")\n",
        "    \n",
        "    if not input_dir or not os.path.exists(input_dir):\n",
        "        print(\"Error: Invalid input directory.\")\n",
        "        return\n",
        "    \n",
        "    watermark_path = input(\"Enter the path to the watermark image you want to apply: \")\n",
        "    if not watermark_path or not os.path.exists(watermark_path):\n",
        "        print(\"Error: Invalid watermark path.\")\n",
        "        return\n",
        "    \n",
        "    # Set output directories\n",
        "    output_unwatermarked = \"output/unwatermarked\"\n",
        "    output_watermarked = \"output/watermarked\"\n",
        "    \n",
        "    # Determine optimal number of workers based on CPU cores\n",
        "    num_workers = min(os.cpu_count() or 1, 8)  # Cap at 8 workers to avoid excessive resource usage\n",
        "    \n",
        "    # Process the images with user-provided watermark\n",
        "    print(f\"\\nProcessing images with watermark: {watermark_path}\")\n",
        "    num_processed = process_images(\n",
        "        input_dir,\n",
        "        watermark_path,\n",
        "        output_unwatermarked,\n",
        "        output_watermarked,\n",
        "        model,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "    \n",
        "    print(f\"Processing complete! Processed {num_processed} images using {num_workers} workers.\")\n",
        "    print(f\"Unwatermarked images saved to: {output_unwatermarked}\")\n",
        "    print(f\"Watermarked images saved to: {output_watermarked}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
