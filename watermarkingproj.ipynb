{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple MPS device\n",
            "Training + Processing mode selected.\n",
            "Using medium quality (balanced).\n",
            "Large dataset detected: limiting to 10000 images for training\n",
            "Large dataset detected: limiting to 10000 images for training\n",
            "Using watermark from: /Users/anurag/development/watermarking/logo.webp\n",
            "Dataset initialized with 10000 clean images and 10000 watermarked images\n",
            "Using watermark from: /Users/anurag/development/watermarking/logo.webp\n",
            "Dataset initialized with 3289 clean images and 3299 watermarked images\n",
            "Training model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 [Train]:  63%|██████▎   | 392/625 [01:11<00:37,  6.24it/s, loss=0.6966]/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch 1/10 [Train]:  88%|████████▊ | 550/625 [01:37<00:12,  6.08it/s, loss=0.7302]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 15336: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 [Train]:  93%|█████████▎| 580/625 [01:42<00:07,  6.06it/s, loss=0.6967]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 18583: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 625/625 [01:50<00:00,  5.67it/s, loss=0.7206]\n",
            "Epoch 1/10 [Val]: 100%|██████████| 206/206 [00:11<00:00, 17.63it/s, val_loss=0.5549, acc=0.9286]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - Train Loss: 0.7242, Val Loss: 0.6996, Val Accuracy: 0.5197, LR: 0.001000\n",
            "New best model saved (val_loss: 0.6996)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 [Train]:  47%|████▋     | 291/625 [00:48<00:54,  6.12it/s, loss=0.7153]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 15336: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 [Train]:  85%|████████▍ | 531/625 [01:28<00:15,  5.92it/s, loss=0.7441]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 18583: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 [Train]: 100%|██████████| 625/625 [01:43<00:00,  6.04it/s, loss=0.7133]\n",
            "Epoch 2/10 [Val]: 100%|██████████| 206/206 [00:09<00:00, 21.35it/s, val_loss=0.8163, acc=0.1429]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 - Train Loss: 0.7105, Val Loss: 0.6988, Val Accuracy: 0.5274, LR: 0.001000\n",
            "New best model saved (val_loss: 0.6988)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 [Train]:  17%|█▋        | 106/625 [00:13<01:06,  7.75it/s, loss=0.7181]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 15336: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 [Train]:  90%|████████▉ | 560/625 [01:23<00:10,  6.11it/s, loss=0.7013]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 18583: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 [Train]: 100%|██████████| 625/625 [01:34<00:00,  6.63it/s, loss=0.7185]\n",
            "Epoch 3/10 [Val]: 100%|██████████| 206/206 [00:11<00:00, 18.22it/s, val_loss=0.4933, acc=1.0000]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 - Train Loss: 0.7075, Val Loss: 0.7069, Val Accuracy: 0.5193, LR: 0.001000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 [Train]:  58%|█████▊    | 360/625 [00:52<00:34,  7.65it/s, loss=0.7271]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 15336: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 [Train]:  97%|█████████▋| 606/625 [01:27<00:03,  6.10it/s, loss=0.7039]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 18583: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 [Train]: 100%|██████████| 625/625 [01:30<00:00,  6.91it/s, loss=0.7043]\n",
            "Epoch 4/10 [Val]: 100%|██████████| 206/206 [00:11<00:00, 18.10it/s, val_loss=0.7471, acc=0.3571]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 - Train Loss: 0.7061, Val Loss: 0.6900, Val Accuracy: 0.5325, LR: 0.001000\n",
            "New best model saved (val_loss: 0.6900)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 [Train]:  62%|██████▏   | 386/625 [01:04<00:39,  6.06it/s, loss=0.7011]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 18583: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 [Train]:  94%|█████████▍| 589/625 [01:38<00:06,  5.79it/s, loss=0.6809]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 15336: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 [Train]: 100%|██████████| 625/625 [01:44<00:00,  5.98it/s, loss=0.7212]\n",
            "Epoch 5/10 [Val]: 100%|██████████| 206/206 [00:11<00:00, 18.52it/s, val_loss=0.6680, acc=0.5000]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 - Train Loss: 0.7050, Val Loss: 0.6861, Val Accuracy: 0.5532, LR: 0.001000\n",
            "New best model saved (val_loss: 0.6861)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 [Train]:   5%|▌         | 34/625 [00:06<01:42,  5.74it/s, loss=0.6682]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 18583: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 [Train]:  39%|███▉      | 245/625 [00:41<01:02,  6.09it/s, loss=0.7402]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 15336: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 [Train]: 100%|██████████| 625/625 [01:44<00:00,  5.97it/s, loss=0.7023]\n",
            "Epoch 6/10 [Val]: 100%|██████████| 206/206 [00:11<00:00, 18.62it/s, val_loss=0.7100, acc=0.4643]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 - Train Loss: 0.7031, Val Loss: 0.6904, Val Accuracy: 0.5387, LR: 0.001000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 [Train]:  60%|█████▉    | 374/625 [01:03<00:44,  5.69it/s, loss=0.6725]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 18583: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 [Train]:  73%|███████▎  | 459/625 [01:17<00:27,  5.96it/s, loss=0.7164]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 15336: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 [Train]: 100%|██████████| 625/625 [01:45<00:00,  5.93it/s, loss=0.7324]\n",
            "Epoch 7/10 [Val]: 100%|██████████| 206/206 [00:11<00:00, 18.61it/s, val_loss=0.5454, acc=0.9643]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 - Train Loss: 0.7048, Val Loss: 0.6922, Val Accuracy: 0.5320, LR: 0.001000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 [Train]:  18%|█▊        | 110/625 [00:19<01:27,  5.86it/s, loss=0.6759]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 18583: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 [Train]:  26%|██▌       | 163/625 [00:27<01:16,  6.00it/s, loss=0.6981]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 15336: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 [Train]: 100%|██████████| 625/625 [01:43<00:00,  6.03it/s, loss=0.7304]\n",
            "Epoch 8/10 [Val]: 100%|██████████| 206/206 [00:11<00:00, 18.16it/s, val_loss=0.6397, acc=0.7500]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 - Train Loss: 0.7037, Val Loss: 0.6832, Val Accuracy: 0.5716, LR: 0.001000\n",
            "New best model saved (val_loss: 0.6832)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 [Train]:  31%|███       | 192/625 [00:31<01:13,  5.92it/s, loss=0.7156]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 18583: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 [Train]:  71%|███████▏  | 446/625 [01:13<00:31,  5.73it/s, loss=0.6805]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 15336: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 [Train]: 100%|██████████| 625/625 [01:44<00:00,  6.00it/s, loss=0.6727]\n",
            "Epoch 9/10 [Val]: 100%|██████████| 206/206 [00:11<00:00, 18.07it/s, val_loss=0.6355, acc=0.6786]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 - Train Loss: 0.7016, Val Loss: 0.6810, Val Accuracy: 0.5758, LR: 0.001000\n",
            "New best model saved (val_loss: 0.6810)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 [Train]:  63%|██████▎   | 394/625 [01:04<00:38,  5.93it/s, loss=0.6880]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 15336: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 [Train]:  89%|████████▊ | 554/625 [01:31<00:11,  5.97it/s, loss=0.7145]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading data at index 18583: image file is truncated (1 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 [Train]: 100%|██████████| 625/625 [01:43<00:00,  6.06it/s, loss=0.6921]\n",
            "Epoch 10/10 [Val]: 100%|██████████| 206/206 [00:11<00:00, 18.03it/s, val_loss=0.6553, acc=0.6071]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 - Train Loss: 0.6994, Val Loss: 0.6801, Val Accuracy: 0.5747, LR: 0.001000\n",
            "New best model saved (val_loss: 0.6801)\n",
            "Model saved to watermark_model.pth\n",
            "\n",
            "--- Watermark Processing ---\n",
            "Processing all 3289 images at once...\n",
            "Processing with CPU using 4 workers, quality=medium\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images: 100%|██████████| 3289/3289 [00:07<00:00, 440.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "----- Processing Summary -----\n",
            "Total images: 3289\n",
            "Successfully processed: 175\n",
            "  - Watermarked: 49\n",
            "  - Unwatermarked: 126\n",
            "Skipped (low confidence): 3114\n",
            "Errors: 0\n",
            "Unwatermarked images saved to: output/unwatermarked\n",
            "Watermarked images saved to: output/watermarked\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from functools import partial\n",
        "import random\n",
        "import numpy as np\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import torch.multiprocessing as mp\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# Set multiprocessing method to spawn for better stability\n",
        "try:\n",
        "    mp.set_start_method('spawn', force=True)\n",
        "except RuntimeError:\n",
        "    pass  # Already set\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Ignore certain warnings to reduce noise\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"TypedStorage is deprecated\")\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"nn.functional.interpolate\")\n",
        "\n",
        "# Use GPU if available with memory management\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    # Clear cache at start\n",
        "    torch.cuda.empty_cache()\n",
        "    # Set device to highest compute capability\n",
        "    max_memory_gpu = 0\n",
        "    max_device_id = 0\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        total_memory = torch.cuda.get_device_properties(i).total_memory\n",
        "        if total_memory > max_memory_gpu:\n",
        "            max_memory_gpu = total_memory\n",
        "            max_device_id = i\n",
        "    device = torch.device(f\"cuda:{max_device_id}\")\n",
        "    print(f\"Using CUDA device {max_device_id} with {max_memory_gpu/1024**3:.1f} GB memory\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"Using Apple MPS device\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "# Optimized HiDDeN model with reduced complexity\n",
        "class OptimizedHiDDeNModel(nn.Module):\n",
        "    def __init__(self, watermark_strength=0.8):\n",
        "        super(OptimizedHiDDeNModel, self).__init__()\n",
        "        self.watermark_strength = watermark_strength\n",
        "        \n",
        "        # Simplified watermark classifier (fewer layers, fewer filters)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Reduced from 64 to 32 filters\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # Reduced from 128 to 64 filters\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))  # Removed one Conv2d layer\n",
        "        )\n",
        "        self.classifier_fc = nn.Linear(64, 1)  # Input size reduced from 256 to 64\n",
        "        \n",
        "        # Simplified encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(6, 32, kernel_size=3, padding=1),  # Reduced from 64 to 32 filters\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding=1),  # Reduced from 128->64 to 32->16\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, 3, kernel_size=3, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Simplified decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Reduced from 64 to 32 filters\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding=1),  # Reduced from 128->64 to 32->16\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, 3, kernel_size=3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Move model to GPU if available\n",
        "        self.to(device)\n",
        "\n",
        "    # Classification with optimized memory usage\n",
        "    def classify(self, image):\n",
        "        features = self.classifier(image)\n",
        "        features = features.view(features.size(0), -1)\n",
        "        return torch.sigmoid(self.classifier_fc(features))\n",
        "\n",
        "    # Encoding with adjustable watermark strength\n",
        "    def encode(self, image, watermark):\n",
        "        if watermark.shape[2:] != image.shape[2:]:\n",
        "            watermark = F.interpolate(watermark, size=image.shape[2:], mode='bilinear', align_corners=False)\n",
        "        combined = torch.cat([image, watermark], dim=1)\n",
        "        encoded_image = image + self.watermark_strength * self.encoder(combined)\n",
        "        encoded_image = torch.clamp(encoded_image, -1, 1)\n",
        "        return encoded_image\n",
        "\n",
        "    def decode(self, watermarked_image):\n",
        "        extracted_watermark = self.decoder(watermarked_image)\n",
        "        return extracted_watermark\n",
        "    \n",
        "    def remove_watermark(self, watermarked_image):\n",
        "        extracted_watermark = self.decode(watermarked_image)\n",
        "        clean_image = watermarked_image - extracted_watermark\n",
        "        clean_image = torch.clamp(clean_image, -1, 1)\n",
        "        return clean_image\n",
        "\n",
        "# Safe image opening with support for various formats\n",
        "def safe_open_image(path):\n",
        "    \"\"\"Safely open images with different formats including RGBA\"\"\"\n",
        "    try:\n",
        "        img = Image.open(path)\n",
        "        if img.mode == 'RGBA':\n",
        "            # Convert RGBA to RGB by compositing on white background\n",
        "            background = Image.new('RGB', img.size, (255, 255, 255))\n",
        "            background.paste(img, mask=img.split()[3])  # Use alpha as mask\n",
        "            return background\n",
        "        elif img.mode != 'RGB':\n",
        "            return img.convert('RGB')\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening image {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Optimized dataset class with better error handling\n",
        "class WatermarkDataset(Dataset):\n",
        "    def __init__(self, clean_dir, watermarked_dir=None, watermark_path=None, transform=None, is_train=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            clean_dir (string): Directory with non-watermarked/clean images.\n",
        "            watermarked_dir (string): Directory with watermarked images.\n",
        "            watermark_path (string): Path to watermark image to use for training.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "            is_train (bool): Whether this is training or validation set.\n",
        "        \"\"\"\n",
        "        self.clean_dir = clean_dir\n",
        "        self.watermarked_dir = watermarked_dir\n",
        "        self.transform = transform\n",
        "        self.is_train = is_train\n",
        "        self.watermark_tensor = None\n",
        "        \n",
        "        # Get all clean image files\n",
        "        self.clean_image_files = []\n",
        "        if os.path.exists(clean_dir):\n",
        "            self.clean_image_files = [f for f in os.listdir(clean_dir)\n",
        "                        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
        "            # Limit dataset size for faster processing if too large\n",
        "            if len(self.clean_image_files) > 10000 and is_train:\n",
        "                print(f\"Large dataset detected: limiting to 10000 images for training\")\n",
        "                self.clean_image_files = self.clean_image_files[:10000]\n",
        "        \n",
        "        # Get all watermarked image files if directory is provided\n",
        "        self.watermarked_image_files = []\n",
        "        if watermarked_dir and os.path.exists(watermarked_dir):\n",
        "            self.watermarked_image_files = [f for f in os.listdir(watermarked_dir)\n",
        "                            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
        "            # Limit dataset size for faster processing if too large\n",
        "            if len(self.watermarked_image_files) > 10000 and is_train:\n",
        "                print(f\"Large dataset detected: limiting to 10000 images for training\")\n",
        "                self.watermarked_image_files = self.watermarked_image_files[:10000]\n",
        "        \n",
        "        # Load watermark once during initialization\n",
        "        if watermark_path and os.path.exists(watermark_path):\n",
        "            try:\n",
        "                watermark_img = safe_open_image(watermark_path)\n",
        "                if watermark_img and transform:\n",
        "                    self.watermark_tensor = transform(watermark_img)\n",
        "                print(f\"Using watermark from: {watermark_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Unable to load watermark: {e}\")\n",
        "                self.watermark_tensor = None\n",
        "        \n",
        "        print(f\"Dataset initialized with {len(self.clean_image_files)} clean images and {len(self.watermarked_image_files)} watermarked images\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        if self.is_train:\n",
        "            # For training, use both clean and watermarked images\n",
        "            return len(self.clean_image_files) + len(self.watermarked_image_files)\n",
        "        else:\n",
        "            # For validation, use all available images\n",
        "            return len(self.clean_image_files) + len(self.watermarked_image_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Determine if we're loading a clean or watermarked image\n",
        "            if idx >= len(self.clean_image_files):\n",
        "                # This is a watermarked image\n",
        "                if len(self.watermarked_image_files) == 0:\n",
        "                    # No watermarked images available, wrap around to clean images\n",
        "                    clean_idx = idx % len(self.clean_image_files)\n",
        "                    img_name = os.path.join(self.clean_dir, self.clean_image_files[clean_idx])\n",
        "                    image = safe_open_image(img_name)\n",
        "                    \n",
        "                    if image is None:\n",
        "                        # Fallback for corrupted images\n",
        "                        return self.__getitem__((idx + 1) % len(self))\n",
        "                    \n",
        "                    if self.transform:\n",
        "                        image = self.transform(image)\n",
        "                    \n",
        "                    # Use a blank watermark if none provided\n",
        "                    if self.watermark_tensor is None:\n",
        "                        watermark = torch.zeros_like(image)\n",
        "                    else:\n",
        "                        watermark = self.watermark_tensor\n",
        "                    \n",
        "                    return {\n",
        "                        'image': image,\n",
        "                        'watermark': watermark,\n",
        "                        'has_watermark': torch.tensor([0.0], dtype=torch.float32)\n",
        "                    }\n",
        "                else:\n",
        "                    # Load actual watermarked image\n",
        "                    watermarked_idx = idx - len(self.clean_image_files)\n",
        "                    watermarked_idx = watermarked_idx % len(self.watermarked_image_files)  # Handle overflow\n",
        "                    img_name = os.path.join(self.watermarked_dir, self.watermarked_image_files[watermarked_idx])\n",
        "                    image = safe_open_image(img_name)\n",
        "                    \n",
        "                    if image is None:\n",
        "                        # Fallback for corrupted images\n",
        "                        return self.__getitem__((idx + 1) % len(self))\n",
        "                    \n",
        "                    if self.transform:\n",
        "                        image = self.transform(image)\n",
        "                    \n",
        "                    # Use a blank watermark if none provided\n",
        "                    if self.watermark_tensor is None:\n",
        "                        watermark = torch.zeros_like(image)\n",
        "                    else:\n",
        "                        watermark = self.watermark_tensor\n",
        "                    \n",
        "                    return {\n",
        "                        'image': image,\n",
        "                        'watermark': watermark,\n",
        "                        'has_watermark': torch.tensor([1.0], dtype=torch.float32)\n",
        "                    }\n",
        "            else:\n",
        "                # This is a clean/non-watermarked image\n",
        "                img_name = os.path.join(self.clean_dir, self.clean_image_files[idx])\n",
        "                image = safe_open_image(img_name)\n",
        "                \n",
        "                if image is None:\n",
        "                    # Fallback for corrupted images\n",
        "                    return self.__getitem__((idx + 1) % len(self))\n",
        "                \n",
        "                if self.transform:\n",
        "                    image = self.transform(image)\n",
        "                \n",
        "                # Use a blank watermark if none provided\n",
        "                if self.watermark_tensor is None:\n",
        "                    watermark = torch.zeros_like(image)\n",
        "                else:\n",
        "                    watermark = self.watermark_tensor\n",
        "                \n",
        "                return {\n",
        "                    'image': image,\n",
        "                    'watermark': watermark,\n",
        "                    'has_watermark': torch.tensor([0.0], dtype=torch.float32)\n",
        "                }\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data at index {idx}: {e}\")\n",
        "            # Return a different sample in case of error\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "\n",
        "# Optimized training function with mixed precision support\n",
        "def optimized_train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.001):\n",
        "    \"\"\"Optimized training function for the HiDDeN model\"\"\"\n",
        "    # Use mixed precision training if CUDA is available\n",
        "    use_amp = torch.cuda.is_available()\n",
        "    scaler = GradScaler() if use_amp else None\n",
        "    \n",
        "    # Use a learning rate scheduler to speed up convergence\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "    \n",
        "    # Loss functions\n",
        "    classifier_criterion = nn.BCELoss()\n",
        "    reconstruction_criterion = nn.MSELoss()\n",
        "    \n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    early_stop_patience = 5  # Stop training if no improvement after this many epochs\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Clear memory before each epoch\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        model.train()\n",
        "        train_total_loss = 0.0\n",
        "        \n",
        "        # Use tqdm for progress bar\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
        "        \n",
        "        for batch in progress_bar:\n",
        "            # Move data to the right device\n",
        "            images = batch['image'].to(device)\n",
        "            watermarks = batch['watermark'].to(device)\n",
        "            has_watermark = batch['has_watermark'].to(device)\n",
        "            \n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Use mixed precision training if available\n",
        "            with autocast() if use_amp else nullcontext():\n",
        "                # Forward pass - classification\n",
        "                watermark_pred = model.classify(images)\n",
        "                classifier_loss = classifier_criterion(watermark_pred, has_watermark)\n",
        "                \n",
        "                # Process based on ground truth\n",
        "                watermarked_indices = has_watermark.squeeze() > 0.5\n",
        "                clean_indices = ~watermarked_indices\n",
        "                \n",
        "                total_loss = classifier_loss\n",
        "                \n",
        "                # Process all images in a single forward pass where possible\n",
        "                if watermarked_indices.sum() > 0:\n",
        "                    watermarked_images = images[watermarked_indices]\n",
        "                    clean_recovered = model.remove_watermark(watermarked_images)\n",
        "                    decoded_watermarks = model.decode(watermarked_images)\n",
        "                    \n",
        "                    # Simplified loss calculation\n",
        "                    removal_loss = 0.1 * torch.mean(torch.abs(\n",
        "                        clean_recovered[:, :, 1:, :] - clean_recovered[:, :, :-1, :]\n",
        "                    ))\n",
        "                    decoder_loss = 0.1 * torch.mean((decoded_watermarks.mean(dim=[2, 3]) - 0.5) ** 2)\n",
        "                    \n",
        "                    total_loss = total_loss + removal_loss + decoder_loss\n",
        "                \n",
        "                if clean_indices.sum() > 0:\n",
        "                    clean_images = images[clean_indices]\n",
        "                    clean_watermarks = watermarks[clean_indices]\n",
        "                    \n",
        "                    encoded_images = model.encode(clean_images, clean_watermarks)\n",
        "                    encoder_loss = reconstruction_criterion(encoded_images, clean_images)\n",
        "                    \n",
        "                    # Simplify this part - combine classification and reconstruction\n",
        "                    decoded_watermarks = model.decode(encoded_images)\n",
        "                    decoder_recovery_loss = reconstruction_criterion(decoded_watermarks, clean_watermarks)\n",
        "                    \n",
        "                    total_loss = total_loss + 0.5 * encoder_loss + 0.5 * decoder_recovery_loss\n",
        "            \n",
        "            # Backward pass and optimize with scaling if using AMP\n",
        "            if use_amp:\n",
        "                scaler.scale(total_loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                total_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            train_total_loss += total_loss.item()\n",
        "            \n",
        "            # Update progress bar\n",
        "            progress_bar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n",
        "        \n",
        "        # Validation with fewer metrics for speed\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_accuracy = 0.0\n",
        "        val_progress_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch in val_progress_bar:\n",
        "                images = batch['image'].to(device)\n",
        "                has_watermark = batch['has_watermark'].to(device)\n",
        "                \n",
        "                watermark_pred = model.classify(images)\n",
        "                batch_val_loss = classifier_criterion(watermark_pred, has_watermark)\n",
        "                val_loss += batch_val_loss.item()\n",
        "                \n",
        "                # Calculate accuracy\n",
        "                predicted = (watermark_pred > 0.5).float()\n",
        "                batch_accuracy = (predicted == has_watermark).float().mean().item()\n",
        "                val_accuracy += batch_accuracy\n",
        "                \n",
        "                # Update progress bar\n",
        "                val_progress_bar.set_postfix({\"val_loss\": f\"{batch_val_loss.item():.4f}\", \"acc\": f\"{batch_accuracy:.4f}\"})\n",
        "        \n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        avg_val_accuracy = val_accuracy / len(val_loader)\n",
        "        \n",
        "        # Update learning rate based on validation loss\n",
        "        scheduler.step(avg_val_loss)\n",
        "        \n",
        "        # Print simple metrics\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
        "              f\"Train Loss: {train_total_loss/len(train_loader):.4f}, \"\n",
        "              f\"Val Loss: {avg_val_loss:.4f}, \"\n",
        "              f\"Val Accuracy: {avg_val_accuracy:.4f}, \"\n",
        "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "        \n",
        "        # Early stopping logic\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "            # Save the best model\n",
        "            torch.save(model.state_dict(), \"watermark_model_best.pth\")\n",
        "            print(f\"New best model saved (val_loss: {best_val_loss:.4f})\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= early_stop_patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                # Load the best model before returning\n",
        "                model.load_state_dict(torch.load(\"watermark_model_best.pth\", map_location=device))\n",
        "                break\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Batch processing for efficient GPU utilization\n",
        "def process_image_batch(batch_files, input_dir, watermark_tensor, output_unwatermarked, output_watermarked, model, quality='medium'):\n",
        "    \"\"\"Process a batch of images at once on GPU\"\"\"\n",
        "    batch_tensors = []\n",
        "    original_sizes = []\n",
        "    filenames = []\n",
        "    \n",
        "    # Prepare batch - determine processing resolution based on quality\n",
        "    if quality == 'low':\n",
        "        process_size = (64, 64)\n",
        "        resize_method = Image.BILINEAR\n",
        "    elif quality == 'medium':\n",
        "        process_size = (128, 128)\n",
        "        resize_method = Image.BILINEAR\n",
        "    else:  # high\n",
        "        process_size = (256, 256)\n",
        "        resize_method = Image.LANCZOS\n",
        "    \n",
        "    # Create transform based on quality setting\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(process_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "    \n",
        "    # Prepare all valid images in batch\n",
        "    for filename in batch_files:\n",
        "        try:\n",
        "            img_path = os.path.join(input_dir, filename)\n",
        "            image = safe_open_image(img_path)\n",
        "            \n",
        "            if image is None:\n",
        "                continue\n",
        "                \n",
        "            original_sizes.append(image.size)\n",
        "            image_tensor = transform(image).unsqueeze(0)\n",
        "            batch_tensors.append(image_tensor)\n",
        "            filenames.append(filename)\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing {filename}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    if not batch_tensors:\n",
        "        return []  # No valid images in this batch\n",
        "    \n",
        "    # Stack tensors into a batch\n",
        "    batch = torch.cat(batch_tensors, dim=0).to(device)\n",
        "    \n",
        "    # Process batch\n",
        "    results = []\n",
        "    with torch.no_grad():\n",
        "        # Classify all at once\n",
        "        probs = model.classify(batch).squeeze()\n",
        "        \n",
        "        # Process each image based on classification\n",
        "        for i, (prob, filename, original_size) in enumerate(zip(probs, filenames, original_sizes)):\n",
        "            try:\n",
        "                image_tensor = batch[i:i+1]\n",
        "                confidence = abs(float(prob) - 0.5) * 2\n",
        "                \n",
        "                # Skip low confidence predictions\n",
        "                if confidence < 0.2:\n",
        "                    results.append(f\"Skipped {filename} (low confidence: {confidence:.2f})\")\n",
        "                    continue\n",
        "                    \n",
        "                has_watermark = prob > 0.5\n",
        "                \n",
        "                if has_watermark:\n",
        "                    # Remove watermark\n",
        "                    cleaned_image = model.remove_watermark(image_tensor)\n",
        "                    cleaned_image = cleaned_image * 0.5 + 0.5  # Denormalize\n",
        "                    cleaned_image_pil = transforms.ToPILImage()(cleaned_image.squeeze(0).cpu())\n",
        "                    cleaned_image_pil = cleaned_image_pil.resize(original_size, resize_method)\n",
        "                    output_path = os.path.join(output_unwatermarked, filename)\n",
        "                    cleaned_image_pil.save(output_path)\n",
        "                    results.append(f\"Removed watermark from: {filename} (confidence: {confidence:.2f})\")\n",
        "                else:\n",
        "                    # Add watermark\n",
        "                    watermarked_image = model.encode(image_tensor, watermark_tensor)\n",
        "                    watermarked_image = watermarked_image * 0.5 + 0.5  # Denormalize\n",
        "                    watermarked_image_pil = transforms.ToPILImage()(watermarked_image.squeeze(0).cpu())\n",
        "                    watermarked_image_pil = watermarked_image_pil.resize(original_size, resize_method)\n",
        "                    output_path = os.path.join(output_watermarked, filename)\n",
        "                    watermarked_image_pil.save(output_path)\n",
        "                    results.append(f\"Added watermark to: {filename} (confidence: {confidence:.2f})\")\n",
        "            except Exception as e:\n",
        "                results.append(f\"Error processing {filename}: {e}\")\n",
        "    \n",
        "    # Clean up GPU memory\n",
        "    del batch\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    return results\n",
        "\n",
        "# Optimized single image processing with quality settings\n",
        "def optimized_process_single_image(filename, input_dir, watermark_img, output_unwatermarked, output_watermarked, model, quality='medium'):\n",
        "    \"\"\"Process a single image with quality settings\"\"\"\n",
        "    \n",
        "    # Determine processing resolution based on quality\n",
        "    if quality == 'low':\n",
        "        process_size = (64, 64)\n",
        "        resize_method = Image.BILINEAR\n",
        "    elif quality == 'medium':\n",
        "        process_size = (128, 128)\n",
        "        resize_method = Image.BILINEAR\n",
        "    else:  # high\n",
        "        process_size = (256, 256)\n",
        "        resize_method = Image.LANCZOS\n",
        "    \n",
        "    img_path = os.path.join(input_dir, filename)\n",
        "\n",
        "    try:\n",
        "        # Load image safely\n",
        "        image = safe_open_image(img_path)\n",
        "        if image is None:\n",
        "            return f\"Error: Could not open {filename}\"\n",
        "            \n",
        "        original_width, original_height = image.size\n",
        "        \n",
        "        # Use quality-based image size for processing\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(process_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ])\n",
        "        \n",
        "        # Pre-scale watermark once\n",
        "        watermark = watermark_img.resize(process_size, Image.BILINEAR)\n",
        "        watermark_tensor = transform(watermark).unsqueeze(0).to(device)\n",
        "        \n",
        "        # Process image\n",
        "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # Classify first - skip processing if confidence is low\n",
        "            watermark_prob = model.classify(image_tensor)\n",
        "            has_watermark = watermark_prob > 0.5\n",
        "            confidence = abs(watermark_prob.item() - 0.5) * 2\n",
        "            \n",
        "            # Only process if confidence is above threshold (avoids processing ambiguous images)\n",
        "            if confidence > 0.2:\n",
        "                if has_watermark.item():\n",
        "                    # Remove watermark\n",
        "                    cleaned_image = model.remove_watermark(image_tensor)\n",
        "                    cleaned_image = cleaned_image * 0.5 + 0.5  # Denormalize\n",
        "                    cleaned_image_pil = transforms.ToPILImage()(cleaned_image.squeeze(0).cpu())\n",
        "                    cleaned_image_pil = cleaned_image_pil.resize((original_width, original_height), resize_method)\n",
        "                    output_path = os.path.join(output_unwatermarked, filename)\n",
        "                    cleaned_image_pil.save(output_path)\n",
        "                    return f\"Removed watermark from: {filename} (confidence: {confidence:.2f})\"\n",
        "                else:\n",
        "                    # Add watermark\n",
        "                    watermarked_image = model.encode(image_tensor, watermark_tensor)\n",
        "                    watermarked_image = watermarked_image * 0.5 + 0.5  # Denormalize\n",
        "                    watermarked_image_pil = transforms.ToPILImage()(watermarked_image.squeeze(0).cpu())\n",
        "                    watermarked_image_pil = watermarked_image_pil.resize((original_width, original_height), resize_method)\n",
        "                    output_path = os.path.join(output_watermarked, filename)\n",
        "                    watermarked_image_pil.save(output_path)\n",
        "                    return f\"Added watermark to: {filename} (confidence: {confidence:.2f})\"\n",
        "            else:\n",
        "                return f\"Skipped {filename} (low confidence: {confidence:.2f})\"\n",
        "    except Exception as e:\n",
        "        return f\"Error processing {filename}: {str(e)}\"\n",
        "\n",
        "# Process in chunks for very large datasets\n",
        "def process_in_chunks(image_files, chunk_size=100, **kwargs):\n",
        "    \"\"\"Process large sets of files in manageable chunks\"\"\"\n",
        "    total_processed = 0\n",
        "    all_results = []\n",
        "    \n",
        "    for i in range(0, len(image_files), chunk_size):\n",
        "        chunk = image_files[i:i+min(chunk_size, len(image_files)-i)]\n",
        "        print(f\"Processing chunk {i//chunk_size + 1}/{(len(image_files)-1)//chunk_size + 1} ({len(chunk)} files)\")\n",
        "        \n",
        "        # Process this chunk\n",
        "        results = optimized_process_images(chunk, **kwargs)\n",
        "        processed = sum(1 for r in results if not r.startswith(\"Skipped\") and not r.startswith(\"Error\"))\n",
        "        total_processed += processed\n",
        "        all_results.extend(results)\n",
        "        \n",
        "        # Clear memory between chunks\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        gc.collect()  # Force garbage collection\n",
        "        \n",
        "    return total_processed, all_results\n",
        "\n",
        "# Main image processing function with GPU batch processing\n",
        "def optimized_process_images(image_files, input_dir, watermark_path, output_unwatermarked, output_watermarked, model, quality='medium', force_cpu=False):\n",
        "    \"\"\"Process images with optimal resource usage\"\"\"\n",
        "    os.makedirs(output_unwatermarked, exist_ok=True)\n",
        "    os.makedirs(output_watermarked, exist_ok=True)\n",
        "\n",
        "    # Load watermark once\n",
        "    try:\n",
        "        watermark_img = safe_open_image(watermark_path)\n",
        "        if watermark_img is None:\n",
        "            print(f\"Error: Could not load watermark from {watermark_path}\")\n",
        "            return 0, []\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading watermark: {str(e)}\")\n",
        "        return 0, []\n",
        "\n",
        "    # No images to process\n",
        "    if not image_files:\n",
        "        print(f\"No image files found to process\")\n",
        "        return 0, []\n",
        "\n",
        "    # Determine processing mode based on available resources\n",
        "    use_gpu_batch = torch.cuda.is_available() and not force_cpu\n",
        "    \n",
        "    results = []\n",
        "    if use_gpu_batch:\n",
        "        # Prepare watermark tensor once for batched processing\n",
        "        # Determine resolution based on quality setting\n",
        "        if quality == 'low':\n",
        "            process_size = (64, 64)\n",
        "        elif quality == 'medium':\n",
        "            process_size = (128, 128)\n",
        "        else:  # high\n",
        "            process_size = (256, 256)\n",
        "            \n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(process_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ])\n",
        "        \n",
        "        watermark = watermark_img.resize(process_size, Image.BILINEAR)\n",
        "        watermark_tensor = transform(watermark).unsqueeze(0).to(device)\n",
        "        \n",
        "        # Calculate optimal batch size based on available GPU memory\n",
        "        available_memory = torch.cuda.get_device_properties(0).total_memory\n",
        "        free_memory = available_memory - torch.cuda.memory_allocated()\n",
        "        \n",
        "        # Estimate memory per image based on resolution\n",
        "        if quality == 'low':\n",
        "            memory_per_image = 6 * 1024 * 1024  # ~6MB per image\n",
        "        elif quality == 'medium':\n",
        "            memory_per_image = 24 * 1024 * 1024  # ~24MB per image\n",
        "        else:\n",
        "            memory_per_image = 96 * 1024 * 1024  # ~96MB per image\n",
        "            \n",
        "        # Reserve 20% of memory for overhead\n",
        "        safe_memory = free_memory * 0.8\n",
        "        batch_size = min(max(1, int(safe_memory // memory_per_image)), 32)  # Cap at 32\n",
        "        \n",
        "        print(f\"Processing with GPU batches of size {batch_size}, quality={quality}\")\n",
        "        \n",
        "        # Process in batches\n",
        "        for i in range(0, len(image_files), batch_size):\n",
        "            batch_files = image_files[i:i+min(batch_size, len(image_files)-i)]\n",
        "            print(f\"Processing batch {i//batch_size + 1}/{(len(image_files)-1)//batch_size + 1} ({len(batch_files)} files)\")\n",
        "            \n",
        "            batch_results = process_image_batch(\n",
        "                batch_files,\n",
        "                input_dir,\n",
        "                watermark_tensor,\n",
        "                output_unwatermarked,\n",
        "                output_watermarked,\n",
        "                model,\n",
        "                quality\n",
        "            )\n",
        "            \n",
        "            results.extend(batch_results)\n",
        "            \n",
        "            # Clean up memory after each batch\n",
        "            torch.cuda.empty_cache()\n",
        "    else:\n",
        "        # Fall back to parallel CPU processing\n",
        "        num_workers = min(os.cpu_count() or 1, 4)  # Cap at 4 workers\n",
        "        print(f\"Processing with CPU using {num_workers} workers, quality={quality}\")\n",
        "        \n",
        "        process_func = partial(\n",
        "            optimized_process_single_image,\n",
        "            input_dir=input_dir,\n",
        "            watermark_img=watermark_img,\n",
        "            output_unwatermarked=output_unwatermarked,\n",
        "            output_watermarked=output_watermarked,\n",
        "            model=model,\n",
        "            quality=quality\n",
        "        )\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
        "            results = list(tqdm(executor.map(process_func, image_files), total=len(image_files), desc=\"Processing images\"))\n",
        "\n",
        "    # Count processed images\n",
        "    processed_count = sum(1 for result in results if not result.startswith(\"Skipped\") and not result.startswith(\"Error\"))\n",
        "    \n",
        "    return processed_count, results\n",
        "\n",
        "# Main function with error handling and user options\n",
        "def optimized_main():\n",
        "    try:\n",
        "        # Define data directories\n",
        "        train_clean_dir = \"wm-nowm/train/no-watermark\"\n",
        "        train_watermarked_dir = \"wm-nowm/train/watermark\"\n",
        "        val_clean_dir = \"wm-nowm/valid/no-watermark\"\n",
        "        val_watermarked_dir = \"wm-nowm/valid/watermark\" \n",
        "        \n",
        "        # Check if directories exist\n",
        "        for directory in [train_clean_dir, train_watermarked_dir, val_clean_dir, val_watermarked_dir]:\n",
        "            if not os.path.exists(directory):\n",
        "                print(f\"Warning: Directory {directory} does not exist.\")\n",
        "        \n",
        "        # Allow user to choose whether to train or just process images\n",
        "        mode = input(\"Choose mode (1: Train + Process, 2: Process only): \").strip()\n",
        "        \n",
        "        if mode == \"2\":\n",
        "            print(\"Processing mode only - will load existing model if available.\")\n",
        "            should_train = False\n",
        "        else:\n",
        "            print(\"Training + Processing mode selected.\")\n",
        "            should_train = True\n",
        "            \n",
        "        # Ask about quality settings\n",
        "        quality_choice = input(\"Choose processing quality (1: Low, 2: Medium, 3: High): \").strip()\n",
        "        if quality_choice == \"1\":\n",
        "            quality = \"low\"\n",
        "            print(\"Using low quality (faster but less accurate).\")\n",
        "        elif quality_choice == \"3\":\n",
        "            quality = \"high\"\n",
        "            print(\"Using high quality (slower but more accurate).\")\n",
        "        else:\n",
        "            quality = \"medium\"\n",
        "            print(\"Using medium quality (balanced).\")\n",
        "        \n",
        "        # Model parameters based on quality\n",
        "        if quality == \"low\":\n",
        "            process_size = (64, 64)\n",
        "        elif quality == \"medium\":\n",
        "            process_size = (128, 128)\n",
        "        else:  # high\n",
        "            process_size = (256, 256)\n",
        "            \n",
        "        # Get watermark path from user for training\n",
        "        if should_train:\n",
        "            watermark_path = input(\"Enter path to watermark image for training (or press Enter to use a blank watermark): \")\n",
        "            if not watermark_path or not os.path.exists(watermark_path):\n",
        "                print(\"No valid watermark path provided. Will use a blank watermark during training.\")\n",
        "                watermark_path = None\n",
        "        \n",
        "            # Optimized transforms with appropriate image size\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize(process_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "            ])\n",
        "            \n",
        "            # Create datasets\n",
        "            train_dataset = WatermarkDataset(\n",
        "                clean_dir=train_clean_dir,\n",
        "                watermarked_dir=train_watermarked_dir,\n",
        "                watermark_path=watermark_path,\n",
        "                transform=transform,\n",
        "                is_train=True\n",
        "            )\n",
        "            \n",
        "            val_dataset = WatermarkDataset(\n",
        "                clean_dir=val_clean_dir, \n",
        "                watermarked_dir=val_watermarked_dir,\n",
        "                watermark_path=watermark_path,\n",
        "                transform=transform,\n",
        "                is_train=False\n",
        "            )\n",
        "            \n",
        "            # Optimize batch size based on system resources and quality\n",
        "            gpu_available = torch.cuda.is_available() or torch.backends.mps.is_available()\n",
        "            \n",
        "            if quality == \"low\":\n",
        "                batch_size = 64 if gpu_available else 32\n",
        "            elif quality == \"medium\":\n",
        "                batch_size = 32 if gpu_available else 16\n",
        "            else:  # high\n",
        "                batch_size = 16 if gpu_available else 8\n",
        "            \n",
        "            # Use only 1 worker for DataLoader to avoid broken pipe errors\n",
        "            num_workers_dl = 0\n",
        "            \n",
        "            # Use pin_memory for faster data transfer to GPU\n",
        "            pin_memory = gpu_available\n",
        "            \n",
        "            train_loader = DataLoader(\n",
        "                train_dataset, \n",
        "                batch_size=batch_size, \n",
        "                shuffle=True, \n",
        "                num_workers=num_workers_dl,\n",
        "                pin_memory=pin_memory,\n",
        "                persistent_workers=False\n",
        "            )\n",
        "            \n",
        "            val_loader = DataLoader(\n",
        "                val_dataset, \n",
        "                batch_size=batch_size, \n",
        "                shuffle=False, \n",
        "                num_workers=num_workers_dl,\n",
        "                pin_memory=pin_memory,\n",
        "                persistent_workers=False\n",
        "            )\n",
        "        \n",
        "        # Create or load model\n",
        "        watermark_strength = 0.5 if quality == \"low\" else 0.8\n",
        "        model = OptimizedHiDDeNModel(watermark_strength=watermark_strength)\n",
        "        \n",
        "        # Path for saved model\n",
        "        model_path = \"watermark_model.pth\"\n",
        "        best_model_path = \"watermark_model_best.pth\"\n",
        "        \n",
        "        # Check for existing model files\n",
        "        if os.path.exists(best_model_path):\n",
        "            print(f\"Loading best model from {best_model_path}\")\n",
        "            model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "        elif os.path.exists(model_path):\n",
        "            print(f\"Loading model from {model_path}\")\n",
        "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "        elif not should_train:\n",
        "            print(\"No model file found. Please run training first or choose an existing model.\")\n",
        "            return\n",
        "            \n",
        "        # Train model if requested\n",
        "        if should_train:\n",
        "            print(\"Training model...\")\n",
        "            try:\n",
        "                # Enable cuDNN benchmarking for faster training if available\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.backends.cudnn.benchmark = True\n",
        "                \n",
        "                model = optimized_train_model(\n",
        "                    model=model,\n",
        "                    train_loader=train_loader,\n",
        "                    val_loader=val_loader,\n",
        "                    num_epochs=10,\n",
        "                    learning_rate=0.001\n",
        "                )\n",
        "                \n",
        "                # Save the final model\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print(f\"Model saved to {model_path}\")\n",
        "                \n",
        "                # Disable benchmarking for inference\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.backends.cudnn.benchmark = False\n",
        "            except Exception as e:\n",
        "                print(f\"Error during training: {e}\")\n",
        "                # If best model exists, load it\n",
        "                if os.path.exists(best_model_path):\n",
        "                    print(f\"Loading last best model from {best_model_path}\")\n",
        "                    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "                else:\n",
        "                    print(\"Training failed and no best model found. Exiting.\")\n",
        "                    return\n",
        "                \n",
        "        # Process user-provided images\n",
        "        print(\"\\n--- Watermark Processing ---\")\n",
        "        input_dir = input(\"Enter the directory path containing images to process: \")\n",
        "        \n",
        "        if not input_dir or not os.path.exists(input_dir):\n",
        "            print(\"Error: Invalid input directory.\")\n",
        "            return\n",
        "        \n",
        "        watermark_path = input(\"Enter the path to the watermark image you want to apply: \")\n",
        "        if not watermark_path or not os.path.exists(watermark_path):\n",
        "            print(\"Error: Invalid watermark path.\")\n",
        "            return\n",
        "        \n",
        "        output_unwatermarked = \"output/unwatermarked\"\n",
        "        output_watermarked = \"output/watermarked\"\n",
        "        \n",
        "        # Get list of image files\n",
        "        image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp'))]\n",
        "        \n",
        "        if len(image_files) == 0:\n",
        "            print(f\"No image files found in {input_dir}\")\n",
        "            return\n",
        "            \n",
        "        # Ask about chunk processing for large datasets\n",
        "        if len(image_files) > 100:\n",
        "            chunked = input(f\"Found {len(image_files)} images. Process in chunks? (y/n): \").strip().lower()\n",
        "            if chunked == 'y':\n",
        "                print(\"Processing in chunks to manage memory...\")\n",
        "                chunk_size = 50  # Choose a reasonable chunk size\n",
        "                total_processed, results = process_in_chunks(\n",
        "                    image_files, \n",
        "                    chunk_size=chunk_size,\n",
        "                    input_dir=input_dir,\n",
        "                    watermark_path=watermark_path,\n",
        "                    output_unwatermarked=output_unwatermarked,\n",
        "                    output_watermarked=output_watermarked,\n",
        "                    model=model,\n",
        "                    quality=quality\n",
        "                )\n",
        "            else:\n",
        "                # Process all at once\n",
        "                print(f\"Processing all {len(image_files)} images at once...\")\n",
        "                total_processed, results = optimized_process_images(\n",
        "                    image_files,\n",
        "                    input_dir=input_dir,\n",
        "                    watermark_path=watermark_path,\n",
        "                    output_unwatermarked=output_unwatermarked,\n",
        "                    output_watermarked=output_watermarked,\n",
        "                    model=model,\n",
        "                    quality=quality\n",
        "                )\n",
        "        else:\n",
        "            # Process all at once for smaller datasets\n",
        "            print(f\"Processing {len(image_files)} images...\")\n",
        "            total_processed, results = optimized_process_images(\n",
        "                image_files,\n",
        "                input_dir=input_dir,\n",
        "                watermark_path=watermark_path,\n",
        "                output_unwatermarked=output_unwatermarked,\n",
        "                output_watermarked=output_watermarked,\n",
        "                model=model,\n",
        "                quality=quality\n",
        "            )\n",
        "        \n",
        "        # Print summary results\n",
        "        skipped = sum(1 for r in results if r.startswith(\"Skipped\"))\n",
        "        errors = sum(1 for r in results if r.startswith(\"Error\"))\n",
        "        watermarked = sum(1 for r in results if \"Added watermark\" in r)\n",
        "        unwatermarked = sum(1 for r in results if \"Removed watermark\" in r)\n",
        "        \n",
        "        print(\"\\n----- Processing Summary -----\")\n",
        "        print(f\"Total images: {len(image_files)}\")\n",
        "        print(f\"Successfully processed: {total_processed}\")\n",
        "        print(f\"  - Watermarked: {watermarked}\")\n",
        "        print(f\"  - Unwatermarked: {unwatermarked}\")\n",
        "        print(f\"Skipped (low confidence): {skipped}\")\n",
        "        print(f\"Errors: {errors}\")\n",
        "        print(f\"Unwatermarked images saved to: {output_unwatermarked}\")\n",
        "        print(f\"Watermarked images saved to: {output_watermarked}\")\n",
        "        \n",
        "        # Ask if user wants to see detailed results\n",
        "        if input(\"Show detailed results? (y/n): \").strip().lower() == 'y':\n",
        "            for result in results:\n",
        "                print(result)\n",
        "    \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation cancelled by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Context manager for null context when not using autocast\n",
        "class nullcontext:\n",
        "    def __enter__(self): return self\n",
        "    def __exit__(self, *args): pass\n",
        "\n",
        "# Main entry point\n",
        "if __name__ == \"__main__\":\n",
        "    optimized_main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
