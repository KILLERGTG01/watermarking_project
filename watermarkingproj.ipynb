{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dlUOTit0DVq",
        "outputId": "aba48180-9eec-4219-b8e9-909b4af23121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n",
            "Downloading watermarked/non-watermarked dataset from Kaggle...\n",
            "Dataset downloaded to: /Users/anurag/.cache/kagglehub/datasets/felicepollano/watermarked-not-watermarked-images/versions/1\n",
            "Warning: Directory /Users/anurag/.cache/kagglehub/datasets/felicepollano/watermarked-not-watermarked-images/versions/1/train/no-watermark not found in dataset\n",
            "Warning: Directory /Users/anurag/.cache/kagglehub/datasets/felicepollano/watermarked-not-watermarked-images/versions/1/train/watermark not found in dataset\n",
            "Dataset preparation complete:\n",
            "- Total images copied: 0\n",
            "- Watermarked images: 0\n",
            "- Non-watermarked images: 0\n",
            "Warning: No images were copied. Check the dataset structure.\n",
            "Training watermark model...\n",
            "- Input directory: input_images\n",
            "- Watermark path: logo.webp\n",
            "- Epochs: 15\n",
            "- Batch size: 16\n",
            "- Learning rate: 0.001\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "No training data found in input directory",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 507\u001b[0m\n\u001b[1;32m    504\u001b[0m input_dir \u001b[38;5;241m=\u001b[39m download_and_prepare_kaggle_dataset(sample_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# First train the model\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwatermark_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwatermark_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Number of training epochs\u001b[39;49;00m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Training batch size\u001b[39;49;00m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Learning rate\u001b[39;49;00m\n\u001b[1;32m    513\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Determine optimal number of workers based on CPU cores\u001b[39;00m\n\u001b[1;32m    516\u001b[0m num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(os\u001b[38;5;241m.\u001b[39mcpu_count(), \u001b[38;5;241m8\u001b[39m)  \u001b[38;5;66;03m# Cap at 8 workers to avoid excessive resource usage\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[1], line 161\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(input_dir, watermark_path, epochs, batch_size, learning_rate, save_path)\u001b[0m\n\u001b[1;32m    158\u001b[0m dataset \u001b[38;5;241m=\u001b[39m WatermarkDataset(input_dir, watermark_path, transform)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo training data found in input directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Split dataset into train and validation sets\u001b[39;00m\n\u001b[1;32m    164\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset))\n",
            "\u001b[0;31mValueError\u001b[0m: No training data found in input directory"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from functools import partial\n",
        "import kagglehub\n",
        "import shutil\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the CNN model with batch normalization and more efficient architecture\n",
        "class WatermarkCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WatermarkCNN, self).__init__()\n",
        "        # Encoder with batch normalization for faster convergence and training stability\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),  # inplace operations save memory\n",
        "            nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        # Decoder with batch normalization\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Move model to GPU if available\n",
        "        self.to(device)\n",
        "\n",
        "    def encode(self, image, watermark):\n",
        "        # Optimize watermark preparation\n",
        "        watermark = watermark.resize((image.shape[3], image.shape[2]))\n",
        "        watermark_tensor = transforms.ToTensor()(watermark).unsqueeze(0).to(device)\n",
        "\n",
        "        # Handle batch processing\n",
        "        if watermark_tensor.shape[0] != image.shape[0]:\n",
        "            watermark_tensor = watermark_tensor.repeat(image.shape[0], 1, 1, 1)\n",
        "\n",
        "        encoded_image = self.encoder(image + watermark_tensor)\n",
        "        return encoded_image\n",
        "\n",
        "    def decode(self, watermarked_image):\n",
        "        decoded_watermark = self.decoder(watermarked_image)\n",
        "        return decoded_watermark\n",
        "    \n",
        "    def forward(self, image, watermark=None):\n",
        "        \"\"\"\n",
        "        Forward pass for training\n",
        "        If watermark is None, only decoding is performed (for detection)\n",
        "        If watermark is provided, both encoding and decoding are performed\n",
        "        \"\"\"\n",
        "        if watermark is not None:\n",
        "            # Resize watermark to match image dimensions\n",
        "            encoded = self.encode(image, watermark)\n",
        "            decoded = self.decode(encoded)\n",
        "            return encoded, decoded\n",
        "        else:\n",
        "            # Just perform decoding (for watermark detection)\n",
        "            decoded = self.decode(image)\n",
        "            return decoded\n",
        "\n",
        "# Custom dataset for watermark images\n",
        "class WatermarkDataset(Dataset):\n",
        "    def __init__(self, input_dir, watermark_path, transform=None):\n",
        "        self.input_dir = input_dir\n",
        "        self.transform = transform or transforms.ToTensor()\n",
        "        \n",
        "        # Load all image paths and identify watermarked vs non-watermarked\n",
        "        self.image_files = []\n",
        "        self.has_watermark = []\n",
        "        \n",
        "        for filename in os.listdir(input_dir):\n",
        "            if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "                continue\n",
        "                \n",
        "            self.image_files.append(filename)\n",
        "            # Detect watermark by filename prefix\n",
        "            self.has_watermark.append(filename.startswith(\"wm_\"))\n",
        "        \n",
        "        # Load watermark image\n",
        "        self.watermark_img = Image.open(watermark_path).convert(\"RGB\")\n",
        "        self.watermark_transform = transforms.ToTensor()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.input_dir, img_name)\n",
        "        \n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image_tensor = self.transform(image)\n",
        "        \n",
        "        has_watermark = self.has_watermark[idx]\n",
        "        \n",
        "        # Convert watermark to tensor for training\n",
        "        watermark_tensor = self.watermark_transform(self.watermark_img)\n",
        "        \n",
        "        # Return the sample\n",
        "        return {\n",
        "            'image': image_tensor, \n",
        "            'watermark': watermark_tensor,\n",
        "            'has_watermark': torch.tensor(has_watermark, dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "# Cache for the model instance to avoid reloading\n",
        "model_cache = None\n",
        "\n",
        "def get_model():\n",
        "    global model_cache\n",
        "    if model_cache is None:\n",
        "        model_cache = WatermarkCNN()\n",
        "        \n",
        "        # Try to load saved model if it exists\n",
        "        model_path = 'watermark_model.pth'\n",
        "        if os.path.exists(model_path):\n",
        "            try:\n",
        "                model_cache.load_state_dict(torch.load(model_path, map_location=device))\n",
        "                print(f\"Loaded pre-trained model from {model_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading model: {str(e)}\")\n",
        "    \n",
        "    return model_cache\n",
        "\n",
        "# Train the watermark model\n",
        "def train_model(input_dir, watermark_path, epochs=10, batch_size=16, learning_rate=0.001, save_path='watermark_model.pth'):\n",
        "    print(f\"Training watermark model...\")\n",
        "    print(f\"- Input directory: {input_dir}\")\n",
        "    print(f\"- Watermark path: {watermark_path}\")\n",
        "    print(f\"- Epochs: {epochs}\")\n",
        "    print(f\"- Batch size: {batch_size}\")\n",
        "    print(f\"- Learning rate: {learning_rate}\")\n",
        "    \n",
        "    # Check if input directory exists and has images\n",
        "    if not os.path.exists(input_dir):\n",
        "        raise FileNotFoundError(f\"Input directory not found: {input_dir}\")\n",
        "    \n",
        "    # Create dataset and data loaders\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),  # Resize to standardize images\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    \n",
        "    dataset = WatermarkDataset(input_dir, watermark_path, transform)\n",
        "    \n",
        "    if len(dataset) == 0:\n",
        "        raise ValueError(\"No training data found in input directory\")\n",
        "    \n",
        "    # Split dataset into train and validation sets\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "    \n",
        "    # Initialize model\n",
        "    model = WatermarkCNN().to(device)\n",
        "    \n",
        "    # Loss functions\n",
        "    mse_loss = nn.MSELoss()\n",
        "    bce_loss = nn.BCELoss()\n",
        "    \n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    \n",
        "    # Training loop\n",
        "    best_val_loss = float('inf')\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        start_time = time.time()\n",
        "        \n",
        "        for batch in train_loader:\n",
        "            # Get batch data\n",
        "            images = batch['image'].to(device)\n",
        "            watermarks = batch['watermark'].to(device)\n",
        "            has_watermark = batch['has_watermark'].to(device)\n",
        "            \n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass\n",
        "            encoded_images, decoded_watermarks = model(images, watermarks)\n",
        "            \n",
        "            # Calculate losses\n",
        "            # 1. Encoding loss - how well can we hide the watermark\n",
        "            encoding_loss = mse_loss(encoded_images, images)\n",
        "            \n",
        "            # 2. Decoding loss - how well can we extract the watermark\n",
        "            detection_loss = bce_loss(decoded_watermarks.mean(dim=(1, 2, 3)), has_watermark)\n",
        "            \n",
        "            # 3. Reconstruction loss - can we recover the original watermark\n",
        "            watermark_recon_loss = mse_loss(decoded_watermarks, \n",
        "                                           watermarks.mean(dim=1, keepdim=True) * has_watermark.view(-1, 1, 1, 1))\n",
        "            \n",
        "            # Total loss - balance between hiding and detecting\n",
        "            total_loss = encoding_loss + 5.0 * detection_loss + watermark_recon_loss\n",
        "            \n",
        "            # Backward pass and optimize\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += total_loss.item()\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                images = batch['image'].to(device)\n",
        "                watermarks = batch['watermark'].to(device)\n",
        "                has_watermark = batch['has_watermark'].to(device)\n",
        "                \n",
        "                encoded_images, decoded_watermarks = model(images, watermarks)\n",
        "                \n",
        "                encoding_loss = mse_loss(encoded_images, images)\n",
        "                detection_loss = bce_loss(decoded_watermarks.mean(dim=(1, 2, 3)), has_watermark)\n",
        "                watermark_recon_loss = mse_loss(decoded_watermarks, \n",
        "                                               watermarks.mean(dim=1, keepdim=True) * has_watermark.view(-1, 1, 1, 1))\n",
        "                \n",
        "                total_loss = encoding_loss + 5.0 * detection_loss + watermark_recon_loss\n",
        "                val_loss += total_loss.item()\n",
        "        \n",
        "        # Calculate average losses\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        \n",
        "        # Print epoch statistics\n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Time: {elapsed_time:.2f}s\")\n",
        "        \n",
        "        # Save best model\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"Saved new best model to {save_path}\")\n",
        "    \n",
        "    print(f\"Training completed! Best validation loss: {best_val_loss:.4f}\")\n",
        "    \n",
        "    # Set the trained model as the cached model\n",
        "    global model_cache\n",
        "    model_cache = model\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Optimized detection with batching support\n",
        "def detect_watermark(image_path):\n",
        "    model = get_model()\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    transform = transforms.ToTensor()\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        watermark = model.decode(image_tensor)\n",
        "        has_watermark = torch.mean(watermark) > 0.05  # Threshold for watermark presence\n",
        "\n",
        "    return has_watermark.item(), image_tensor\n",
        "\n",
        "# Optimized watermark removal\n",
        "def remove_watermark(image_tensor):\n",
        "    model = get_model()\n",
        "    with torch.no_grad():\n",
        "        watermark = model.decode(image_tensor)\n",
        "        cleaned_image = image_tensor - watermark\n",
        "    return cleaned_image\n",
        "\n",
        "# Optimized watermark addition\n",
        "def add_watermark(image_tensor, watermark):\n",
        "    model = get_model()\n",
        "    return model.encode(image_tensor, watermark)\n",
        "\n",
        "# Process single image\n",
        "def process_single_image(filename, input_dir, watermark_img, output_unwatermarked, output_watermarked):\n",
        "    img_path = os.path.join(input_dir, filename)\n",
        "\n",
        "    try:\n",
        "        has_watermark, image_tensor = detect_watermark(img_path)\n",
        "\n",
        "        if has_watermark:\n",
        "            cleaned_image = remove_watermark(image_tensor)\n",
        "            cleaned_image_pil = transforms.ToPILImage()(cleaned_image.squeeze(0).cpu())\n",
        "            output_path = os.path.join(output_unwatermarked, filename)\n",
        "            cleaned_image_pil.save(output_path)\n",
        "            return f\"Removed watermark from: {filename}\"\n",
        "        else:\n",
        "            watermarked_image = add_watermark(image_tensor, watermark_img)\n",
        "            watermarked_image_pil = transforms.ToPILImage()(watermarked_image.squeeze(0).cpu())\n",
        "            output_path = os.path.join(output_watermarked, filename)\n",
        "            watermarked_image_pil.save(output_path)\n",
        "            return f\"Added watermark to: {filename}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error processing {filename}: {str(e)}\"\n",
        "\n",
        "# Main processing function with parallel execution\n",
        "def process_images(input_dir, watermark_path, output_unwatermarked, output_watermarked, num_workers=None):\n",
        "    # Create output directories if they don't exist\n",
        "    os.makedirs(output_unwatermarked, exist_ok=True)\n",
        "    os.makedirs(output_watermarked, exist_ok=True)\n",
        "\n",
        "    # Verify watermark exists\n",
        "    if not os.path.exists(watermark_path):\n",
        "        raise FileNotFoundError(f\"Watermark image not found: {watermark_path}\")\n",
        "    \n",
        "    # Load watermark once\n",
        "    try:\n",
        "        watermark_img = Image.open(watermark_path).convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error loading watermark image: {str(e)}\")\n",
        "\n",
        "    # Get list of image files\n",
        "    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
        "    \n",
        "    if not image_files:\n",
        "        print(f\"No image files found in {input_dir}\")\n",
        "        return 0\n",
        "\n",
        "    # Process images in parallel\n",
        "    process_func = partial(\n",
        "        process_single_image,\n",
        "        input_dir=input_dir,\n",
        "        watermark_img=watermark_img,\n",
        "        output_unwatermarked=output_unwatermarked,\n",
        "        output_watermarked=output_watermarked\n",
        "    )\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
        "        results = list(executor.map(process_func, image_files))\n",
        "\n",
        "    # Print results\n",
        "    for result in results:\n",
        "        print(result)\n",
        "\n",
        "    return len(image_files)\n",
        "\n",
        "# Function to download and prepare Kaggle dataset\n",
        "def download_and_prepare_kaggle_dataset(use_train=True, use_valid=False, sample_limit=None):\n",
        "    print(\"Downloading watermarked/non-watermarked dataset from Kaggle...\")\n",
        "    dataset_path = kagglehub.dataset_download(\"felicepollano/watermarked-not-watermarked-images\")\n",
        "    print(f\"Dataset downloaded to: {dataset_path}\")\n",
        "\n",
        "    # Create input directory for our processing\n",
        "    input_dir = \"input_images\"\n",
        "    os.makedirs(input_dir, exist_ok=True)\n",
        "    \n",
        "    # Define source directories based on dataset structure\n",
        "    source_dirs = []\n",
        "    \n",
        "    if use_train:\n",
        "        source_dirs.append(os.path.join(dataset_path, \"train\", \"no-watermark\"))\n",
        "        source_dirs.append(os.path.join(dataset_path, \"train\", \"watermark\"))\n",
        "    \n",
        "    if use_valid:\n",
        "        source_dirs.append(os.path.join(dataset_path, \"valid\", \"no-watermark\"))\n",
        "        source_dirs.append(os.path.join(dataset_path, \"valid\", \"watermark\"))\n",
        "    \n",
        "    # Track statistics for reporting\n",
        "    copied_count = 0\n",
        "    total_watermarked = 0\n",
        "    total_non_watermarked = 0\n",
        "    \n",
        "    # Process each source directory\n",
        "    for source_dir in source_dirs:\n",
        "        if not os.path.exists(source_dir):\n",
        "            print(f\"Warning: Directory {source_dir} not found in dataset\")\n",
        "            continue\n",
        "            \n",
        "        # Determine if this is a watermarked directory\n",
        "        is_watermark_dir = os.path.basename(source_dir) == \"watermark\"\n",
        "        \n",
        "        # Get all image files in this directory\n",
        "        image_files = [f for f in os.listdir(source_dir) \n",
        "                      if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
        "        \n",
        "        # Apply sample limit if specified\n",
        "        if sample_limit is not None and len(image_files) > sample_limit:\n",
        "            random.shuffle(image_files)  # Randomize to get a representative sample\n",
        "            image_files = image_files[:sample_limit]\n",
        "        \n",
        "        # Prefix to avoid filename collisions and track source\n",
        "        prefix = \"wm_\" if is_watermark_dir else \"nowm_\"\n",
        "        \n",
        "        # Copy files to input directory with appropriate prefix\n",
        "        for file in image_files:\n",
        "            source_path = os.path.join(source_dir, file)\n",
        "            # Add prefix to avoid filename collisions\n",
        "            dest_name = f\"{prefix}{file}\"\n",
        "            dest_path = os.path.join(input_dir, dest_name)\n",
        "            \n",
        "            shutil.copy2(source_path, dest_path)\n",
        "            copied_count += 1\n",
        "            \n",
        "            if is_watermark_dir:\n",
        "                total_watermarked += 1\n",
        "            else:\n",
        "                total_non_watermarked += 1\n",
        "    \n",
        "    # Print statistics\n",
        "    print(f\"Dataset preparation complete:\")\n",
        "    print(f\"- Total images copied: {copied_count}\")\n",
        "    print(f\"- Watermarked images: {total_watermarked}\")\n",
        "    print(f\"- Non-watermarked images: {total_non_watermarked}\")\n",
        "    \n",
        "    if copied_count == 0:\n",
        "        print(\"Warning: No images were copied. Check the dataset structure.\")\n",
        "    \n",
        "    return input_dir\n",
        "\n",
        "def run_with_params(watermark_path, input_dir=None, output_unwatermarked='output/unwatermarked', \n",
        "                  output_watermarked='output/watermarked', workers=None, train=True, \n",
        "                  epochs=10, batch_size=16, learning_rate=0.001,\n",
        "                  use_train=True, use_valid=False, sample_limit=50):\n",
        "    \n",
        "    # Get input directory\n",
        "    if input_dir is None:\n",
        "        # Download and prepare the Kaggle dataset if no input directory provided\n",
        "        input_dir = download_and_prepare_kaggle_dataset(use_train, use_valid, sample_limit)\n",
        "    \n",
        "    # Ensure the input directory exists\n",
        "    if not os.path.exists(input_dir):\n",
        "        raise FileNotFoundError(f\"Input directory not found: {input_dir}\")\n",
        "    \n",
        "    # Verify watermark path\n",
        "    if not os.path.exists(watermark_path):\n",
        "        raise FileNotFoundError(f\"Watermark image not found: {watermark_path}\")\n",
        "    \n",
        "    # Determine optimal number of workers if not specified\n",
        "    if workers is None:\n",
        "        workers = min(os.cpu_count(), 8)  # Cap at 8 workers to avoid excessive resource usage\n",
        "    \n",
        "    print(f\"Processing with the following settings:\")\n",
        "    print(f\"- Input directory: {input_dir}\")\n",
        "    print(f\"- Watermark image: {watermark_path}\")\n",
        "    print(f\"- Output directory (unwatermarked): {output_unwatermarked}\")\n",
        "    print(f\"- Output directory (watermarked): {output_watermarked}\")\n",
        "    print(f\"- Workers: {workers}\")\n",
        "    print(f\"- Device: {device}\")\n",
        "    \n",
        "    try:\n",
        "        # First, train the model if requested\n",
        "        if train:\n",
        "            model = train_model(input_dir, watermark_path, epochs, batch_size, learning_rate)\n",
        "        else:\n",
        "            # Just load the model\n",
        "            model = get_model()\n",
        "        \n",
        "        # Process the images\n",
        "        num_processed = process_images(\n",
        "            input_dir,\n",
        "            watermark_path,\n",
        "            output_unwatermarked,\n",
        "            output_watermarked,\n",
        "            num_workers=workers\n",
        "        )\n",
        "        \n",
        "        print(f\"Processing complete! Processed {num_processed} images using {workers} workers.\")\n",
        "        return num_processed\n",
        "    except Exception as e:\n",
        "        print(f\"Error during processing: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return 0\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths and directories\n",
        "    watermark_path = \"logo.webp\"  # Use your watermark image\n",
        "    output_unwatermarked = \"output/unwatermarked\"\n",
        "    output_watermarked = \"output/watermarked\"\n",
        "\n",
        "    # Check if watermark image exists, if not create a simple one\n",
        "    if not os.path.exists(watermark_path):\n",
        "        print(\"Creating a sample watermark image...\")\n",
        "        from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "        # Create a blank image with transparent background\n",
        "        watermark = Image.new('RGBA', (200, 100), (255, 255, 255, 0))\n",
        "        draw = ImageDraw.Draw(watermark)\n",
        "\n",
        "        # Draw text on the image\n",
        "        draw.text((10, 10), \"WATERMARK\", fill=(255, 255, 255, 128))\n",
        "\n",
        "        # Save as PNG to preserve transparency\n",
        "        watermark = watermark.convert(\"RGB\")\n",
        "        watermark.save(watermark_path)\n",
        "        print(f\"Sample watermark created at {watermark_path}\")\n",
        "\n",
        "    # Download the dataset\n",
        "    input_dir = download_and_prepare_kaggle_dataset(sample_limit=100)\n",
        "    \n",
        "    # First train the model\n",
        "    model = train_model(\n",
        "        input_dir=input_dir,\n",
        "        watermark_path=watermark_path,\n",
        "        epochs=15,           # Number of training epochs\n",
        "        batch_size=16,       # Training batch size\n",
        "        learning_rate=0.001  # Learning rate\n",
        "    )\n",
        "    \n",
        "    # Determine optimal number of workers based on CPU cores\n",
        "    num_workers = min(os.cpu_count(), 8)  # Cap at 8 workers to avoid excessive resource usage\n",
        "\n",
        "    # Process the images after training\n",
        "    num_processed = process_images(\n",
        "        input_dir,\n",
        "        watermark_path,\n",
        "        output_unwatermarked,\n",
        "        output_watermarked,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    print(f\"Processing complete! Processed {num_processed} images using {num_workers} workers.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
