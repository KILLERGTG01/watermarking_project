{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple MPS device\n",
            "Processing mode only - will load existing model if available.\n",
            "Using high quality (slower but more accurate).\n",
            "Loading best model from watermark_model_best.pth\n",
            "\n",
            "--- Watermark Processing ---\n",
            "Processing all 6481 images at once...\n",
            "Processing with CPU using 4 workers, quality=high\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images: 100%|██████████| 6481/6481 [00:39<00:00, 163.38it/s]\n",
            "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An unexpected error occurred: not enough values to unpack (expected 4, got 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/var/folders/p_/s7q2x6rd6fvb57rvf2tzkv6r0000gn/T/ipykernel_86090/3474984254.py\", line 1235, in optimized_main\n",
            "    total_processed, results, true_labels, pred_labels = optimized_process_images(\n",
            "                                                         ~~~~~~~~~~~~~~~~~~~~~~~~^\n",
            "        image_files,\n",
            "        ^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "        create_visualizations=True\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/var/folders/p_/s7q2x6rd6fvb57rvf2tzkv6r0000gn/T/ipykernel_86090/3474984254.py\", line 1005, in optimized_process_images\n",
            "    create_confusion_matrix(true_labels, predicted_labels)\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/var/folders/p_/s7q2x6rd6fvb57rvf2tzkv6r0000gn/T/ipykernel_86090/3474984254.py\", line 220, in create_confusion_matrix\n",
            "    tn, fp, fn, tp = cm.ravel()\n",
            "    ^^^^^^^^^^^^^^\n",
            "ValueError: not enough values to unpack (expected 4, got 1)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image,ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from functools import partial\n",
        "import random\n",
        "import numpy as np\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import torch.multiprocessing as mp\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "from scipy import fftpack\n",
        "\n",
        "# Set multiprocessing method to spawn for better stability\n",
        "try:\n",
        "    mp.set_start_method('spawn', force=True)\n",
        "except RuntimeError:\n",
        "    pass  # Already set\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Ignore certain warnings to reduce noise\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"TypedStorage is deprecated\")\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"nn.functional.interpolate\")\n",
        "\n",
        "# Use GPU if available with memory management\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    # Clear cache at start\n",
        "    torch.cuda.empty_cache()\n",
        "    # Set device to highest compute capability\n",
        "    max_memory_gpu = 0\n",
        "    max_device_id = 0\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        total_memory = torch.cuda.get_device_properties(i).total_memory\n",
        "        if total_memory > max_memory_gpu:\n",
        "            max_memory_gpu = total_memory\n",
        "            max_device_id = i\n",
        "    device = torch.device(f\"cuda:{max_device_id}\")\n",
        "    print(f\"Using CUDA device {max_device_id} with {max_memory_gpu/1024**3:.1f} GB memory\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"Using Apple MPS device\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "# Optimized HiDDeN model with reduced complexity\n",
        "class OptimizedHiDDeNModel(nn.Module):\n",
        "    def __init__(self, watermark_strength=0.8):\n",
        "        super(OptimizedHiDDeNModel, self).__init__()\n",
        "        self.watermark_strength = watermark_strength\n",
        "        \n",
        "        # Simplified watermark classifier (fewer layers, fewer filters)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Reduced from 64 to 32 filters\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # Reduced from 128 to 64 filters\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))  # Removed one Conv2d layer\n",
        "        )\n",
        "        self.classifier_fc = nn.Linear(64, 1)  # Input size reduced from 256 to 64\n",
        "        \n",
        "        # Simplified encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(6, 32, kernel_size=3, padding=1),  # Reduced from 64 to 32 filters\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding=1),  # Reduced from 128->64 to 32->16\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, 3, kernel_size=3, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Simplified decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Reduced from 64 to 32 filters\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding=1),  # Reduced from 128->64 to 32->16\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, 3, kernel_size=3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Move model to GPU if available\n",
        "        self.to(device)\n",
        "\n",
        "    # Classification with optimized memory usage\n",
        "    def classify(self, image):\n",
        "        features = self.classifier(image)\n",
        "        features = features.view(features.size(0), -1)\n",
        "        return torch.sigmoid(self.classifier_fc(features))\n",
        "\n",
        "    # Encoding with adjustable watermark strength\n",
        "    def encode(self, image, watermark):\n",
        "        if watermark.shape[2:] != image.shape[2:]:\n",
        "            watermark = F.interpolate(watermark, size=image.shape[2:], mode='bilinear', align_corners=False)\n",
        "        combined = torch.cat([image, watermark], dim=1)\n",
        "        encoded_image = image + self.watermark_strength * self.encoder(combined)\n",
        "        encoded_image = torch.clamp(encoded_image, -1, 1)\n",
        "        return encoded_image\n",
        "\n",
        "    def decode(self, watermarked_image):\n",
        "        extracted_watermark = self.decoder(watermarked_image)\n",
        "        return extracted_watermark\n",
        "    \n",
        "    def remove_watermark(self, watermarked_image):\n",
        "        extracted_watermark = self.decode(watermarked_image)\n",
        "        clean_image = watermarked_image - extracted_watermark\n",
        "        clean_image = torch.clamp(clean_image, -1, 1)\n",
        "        return clean_image\n",
        "\n",
        "# Safe image opening with support for various formats\n",
        "def safe_open_image(path):\n",
        "    \"\"\"Safely open images with different formats including RGBA\"\"\"\n",
        "    try:\n",
        "        img = Image.open(path)\n",
        "        if img.mode == 'RGBA':\n",
        "            # Convert RGBA to RGB by compositing on white background\n",
        "            background = Image.new('RGB', img.size, (255, 255, 255))\n",
        "            background.paste(img, mask=img.split()[3])  # Use alpha as mask\n",
        "            return background\n",
        "        elif img.mode != 'RGB':\n",
        "            return img.convert('RGB')\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening image {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Add visualization function for dataset distribution\n",
        "def visualize_dataset_distribution(train_dataset, val_dataset, output_dir=\"visualizations\"):\n",
        "    \"\"\"\n",
        "    Create bar graphs showing distribution of watermarked and unwatermarked images\n",
        "    in both training and validation datasets.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    # Count watermarked and unwatermarked images in training set\n",
        "    train_wm_count = len(train_dataset.watermarked_image_files)\n",
        "    train_clean_count = len(train_dataset.clean_image_files)\n",
        "    \n",
        "    # Count watermarked and unwatermarked images in validation set\n",
        "    val_wm_count = len(val_dataset.watermarked_image_files)\n",
        "    val_clean_count = len(val_dataset.clean_image_files)\n",
        "    \n",
        "    # Create figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    \n",
        "    # Training set bar graph\n",
        "    categories = ['Watermarked', 'Unwatermarked']\n",
        "    counts = [train_wm_count, train_clean_count]\n",
        "    ax1.bar(categories, counts, color=['#ff6b6b', '#4ecdc4'])\n",
        "    ax1.set_title('Training Dataset Distribution')\n",
        "    ax1.set_ylabel('Number of Images')\n",
        "    for i, count in enumerate(counts):\n",
        "        ax1.text(i, count + 0.1, str(count), ha='center')\n",
        "    \n",
        "    # Validation set bar graph\n",
        "    counts = [val_wm_count, val_clean_count]\n",
        "    ax2.bar(categories, counts, color=['#ff6b6b', '#4ecdc4'])\n",
        "    ax2.set_title('Validation Dataset Distribution')\n",
        "    ax2.set_ylabel('Number of Images')\n",
        "    for i, count in enumerate(counts):\n",
        "        ax2.text(i, count + 0.1, str(count), ha='center')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'dataset_distribution.png'), dpi=300)\n",
        "    plt.close()\n",
        "    \n",
        "    print(f\"Dataset distribution visualization saved to {os.path.join(output_dir, 'dataset_distribution.png')}\")\n",
        "\n",
        "# Function to create confusion matrix\n",
        "def create_confusion_matrix(true_labels, predicted_labels, output_dir=\"visualizations\"):\n",
        "    \"\"\"\n",
        "    Create and save a confusion matrix visualization.\n",
        "    true_labels: List of ground truth labels (1 for watermarked, 0 for unwatermarked)\n",
        "    predicted_labels: List of predicted labels (1 for watermarked, 0 for unwatermarked)\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "    \n",
        "    # Set up plot\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
        "                xticklabels=[\"Unwatermarked\", \"Watermarked\"],\n",
        "                yticklabels=[\"Unwatermarked\", \"Watermarked\"])\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(\"Confusion Matrix for Watermark Detection\")\n",
        "    \n",
        "    # Save the plot\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'), dpi=300)\n",
        "    plt.close()\n",
        "    \n",
        "    # Calculate metrics\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    \n",
        "    print(\"\\n----- Confusion Matrix Statistics -----\")\n",
        "    print(f\"True Positives (correctly identified as watermarked): {tp}\")\n",
        "    print(f\"True Negatives (correctly identified as unwatermarked): {tn}\")\n",
        "    print(f\"False Positives (incorrectly identified as watermarked): {fp}\")\n",
        "    print(f\"False Negatives (incorrectly identified as unwatermarked): {fn}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    \n",
        "    print(f\"Confusion matrix visualization saved to {os.path.join(output_dir, 'confusion_matrix.png')}\")\n",
        "    \n",
        "    return cm\n",
        "\n",
        "# Function to create a heat correlation map\n",
        "def create_correlation_heatmap(model, images, output_dir=\"visualizations\"):\n",
        "    \"\"\"\n",
        "    Create a correlation heatmap showing relationships between image features\n",
        "    and watermark detection confidence.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    # Extract features from a sample of images\n",
        "    features = []\n",
        "    predictions = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for img in images:\n",
        "            # Move image to device\n",
        "            img_tensor = img.to(device)\n",
        "            \n",
        "            # Get model prediction\n",
        "            pred = model.classify(img_tensor).cpu().item()\n",
        "            predictions.append(pred)\n",
        "            \n",
        "            # Extract basic image statistics as features\n",
        "            img_np = img.squeeze(0).cpu().numpy()\n",
        "            img_np = (img_np * 0.5) + 0.5  # Denormalize\n",
        "            \n",
        "            # Calculate various image statistics\n",
        "            means = img_np.mean(axis=(1, 2))  # Channel means\n",
        "            stds = img_np.std(axis=(1, 2))    # Channel standard deviations\n",
        "            \n",
        "            # Calculate texture features (simplified)\n",
        "            r_g_corr = np.corrcoef(img_np[0].flatten(), img_np[1].flatten())[0, 1]\n",
        "            r_b_corr = np.corrcoef(img_np[0].flatten(), img_np[2].flatten())[0, 1]\n",
        "            g_b_corr = np.corrcoef(img_np[1].flatten(), img_np[2].flatten())[0, 1]\n",
        "            \n",
        "            # Calculate some frequency domain features\n",
        "            r_fft = np.abs(fftpack.fft2(img_np[0]))\n",
        "            g_fft = np.abs(fftpack.fft2(img_np[1]))\n",
        "            b_fft = np.abs(fftpack.fft2(img_np[2]))\n",
        "            \n",
        "            r_high_freq = r_fft[r_fft.shape[0]//2:, r_fft.shape[1]//2:].mean()\n",
        "            g_high_freq = g_fft[g_fft.shape[0]//2:, g_fft.shape[1]//2:].mean()\n",
        "            b_high_freq = b_fft[b_fft.shape[0]//2:, b_fft.shape[1]//2:].mean()\n",
        "            \n",
        "            # Combine features\n",
        "            feature_vector = [\n",
        "                means[0], means[1], means[2],  # RGB means\n",
        "                stds[0], stds[1], stds[2],     # RGB standard deviations\n",
        "                r_g_corr, r_b_corr, g_b_corr,  # Color correlations\n",
        "                r_high_freq, g_high_freq, b_high_freq  # High frequency components\n",
        "            ]\n",
        "            features.append(feature_vector)\n",
        "    \n",
        "    # Create dataframe with features and prediction\n",
        "    columns = [\n",
        "        'R_Mean', 'G_Mean', 'B_Mean',\n",
        "        'R_Std', 'G_Std', 'B_Std',\n",
        "        'R_G_Corr', 'R_B_Corr', 'G_B_Corr',\n",
        "        'R_HighFreq', 'G_HighFreq', 'B_HighFreq',\n",
        "        'WM_Confidence'\n",
        "    ]\n",
        "    \n",
        "    data = np.hstack([features, np.array(predictions).reshape(-1, 1)])\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    \n",
        "    # Calculate correlation\n",
        "    corr = df.corr()\n",
        "    \n",
        "    # Plot heatmap\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "    sns.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", cmap=\"coolwarm\", \n",
        "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "    plt.title(\"Feature Correlation Heatmap\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'correlation_heatmap.png'), dpi=300)\n",
        "    plt.close()\n",
        "    \n",
        "    print(f\"Correlation heatmap saved to {os.path.join(output_dir, 'correlation_heatmap.png')}\")\n",
        "    \n",
        "    return corr\n",
        "\n",
        "# Optimized dataset class with better error handling\n",
        "class WatermarkDataset(Dataset):\n",
        "    def __init__(self, clean_dir, watermarked_dir=None, watermark_path=None, transform=None, is_train=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            clean_dir (string): Directory with non-watermarked/clean images.\n",
        "            watermarked_dir (string): Directory with watermarked images.\n",
        "            watermark_path (string): Path to watermark image to use for training.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "            is_train (bool): Whether this is training or validation set.\n",
        "        \"\"\"\n",
        "        self.clean_dir = clean_dir\n",
        "        self.watermarked_dir = watermarked_dir\n",
        "        self.transform = transform\n",
        "        self.is_train = is_train\n",
        "        self.watermark_tensor = None\n",
        "        \n",
        "        # Get all clean image files\n",
        "        self.clean_image_files = []\n",
        "        if os.path.exists(clean_dir):\n",
        "            self.clean_image_files = [f for f in os.listdir(clean_dir)\n",
        "                        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
        "            # Limit dataset size for faster processing if too large\n",
        "            if len(self.clean_image_files) > 10000 and is_train:\n",
        "                print(f\"Large dataset detected: limiting to 10000 images for training\")\n",
        "                self.clean_image_files = self.clean_image_files[:10000]\n",
        "        \n",
        "        # Get all watermarked image files if directory is provided\n",
        "        self.watermarked_image_files = []\n",
        "        if watermarked_dir and os.path.exists(watermarked_dir):\n",
        "            self.watermarked_image_files = [f for f in os.listdir(watermarked_dir)\n",
        "                            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
        "            # Limit dataset size for faster processing if too large\n",
        "            if len(self.watermarked_image_files) > 10000 and is_train:\n",
        "                print(f\"Large dataset detected: limiting to 10000 images for training\")\n",
        "                self.watermarked_image_files = self.watermarked_image_files[:10000]\n",
        "        \n",
        "        # Load watermark once during initialization\n",
        "        if watermark_path and os.path.exists(watermark_path):\n",
        "            try:\n",
        "                watermark_img = safe_open_image(watermark_path)\n",
        "                if watermark_img and transform:\n",
        "                    self.watermark_tensor = transform(watermark_img)\n",
        "                print(f\"Using watermark from: {watermark_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Unable to load watermark: {e}\")\n",
        "                self.watermark_tensor = None\n",
        "        \n",
        "        print(f\"Dataset initialized with {len(self.clean_image_files)} clean images and {len(self.watermarked_image_files)} watermarked images\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        if self.is_train:\n",
        "            # For training, use both clean and watermarked images\n",
        "            return len(self.clean_image_files) + len(self.watermarked_image_files)\n",
        "        else:\n",
        "            # For validation, use all available images\n",
        "            return len(self.clean_image_files) + len(self.watermarked_image_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Determine if we're loading a clean or watermarked image\n",
        "            if idx >= len(self.clean_image_files):\n",
        "                # This is a watermarked image\n",
        "                if len(self.watermarked_image_files) == 0:\n",
        "                    # No watermarked images available, wrap around to clean images\n",
        "                    clean_idx = idx % len(self.clean_image_files)\n",
        "                    img_name = os.path.join(self.clean_dir, self.clean_image_files[clean_idx])\n",
        "                    image = safe_open_image(img_name)\n",
        "                    \n",
        "                    if image is None:\n",
        "                        # Fallback for corrupted images\n",
        "                        return self.__getitem__((idx + 1) % len(self))\n",
        "                    \n",
        "                    if self.transform:\n",
        "                        image = self.transform(image)\n",
        "                    \n",
        "                    # Use a blank watermark if none provided\n",
        "                    if self.watermark_tensor is None:\n",
        "                        watermark = torch.zeros_like(image)\n",
        "                    else:\n",
        "                        watermark = self.watermark_tensor\n",
        "                    \n",
        "                    return {\n",
        "                        'image': image,\n",
        "                        'watermark': watermark,\n",
        "                        'has_watermark': torch.tensor([0.0], dtype=torch.float32)\n",
        "                    }\n",
        "                else:\n",
        "                    # Load actual watermarked image\n",
        "                    watermarked_idx = idx - len(self.clean_image_files)\n",
        "                    watermarked_idx = watermarked_idx % len(self.watermarked_image_files)  # Handle overflow\n",
        "                    img_name = os.path.join(self.watermarked_dir, self.watermarked_image_files[watermarked_idx])\n",
        "                    image = safe_open_image(img_name)\n",
        "                    \n",
        "                    if image is None:\n",
        "                        # Fallback for corrupted images\n",
        "                        return self.__getitem__((idx + 1) % len(self))\n",
        "                    \n",
        "                    if self.transform:\n",
        "                        image = self.transform(image)\n",
        "                    \n",
        "                    # Use a blank watermark if none provided\n",
        "                    if self.watermark_tensor is None:\n",
        "                        watermark = torch.zeros_like(image)\n",
        "                    else:\n",
        "                        watermark = self.watermark_tensor\n",
        "                    \n",
        "                    return {\n",
        "                        'image': image,\n",
        "                        'watermark': watermark,\n",
        "                        'has_watermark': torch.tensor([1.0], dtype=torch.float32)\n",
        "                    }\n",
        "            else:\n",
        "                # This is a clean/non-watermarked image\n",
        "                img_name = os.path.join(self.clean_dir, self.clean_image_files[idx])\n",
        "                image = safe_open_image(img_name)\n",
        "                \n",
        "                if image is None:\n",
        "                    # Fallback for corrupted images\n",
        "                    return self.__getitem__((idx + 1) % len(self))\n",
        "                \n",
        "                if self.transform:\n",
        "                    image = self.transform(image)\n",
        "                \n",
        "                # Use a blank watermark if none provided\n",
        "                if self.watermark_tensor is None:\n",
        "                    watermark = torch.zeros_like(image)\n",
        "                else:\n",
        "                    watermark = self.watermark_tensor\n",
        "                \n",
        "                return {\n",
        "                    'image': image,\n",
        "                    'watermark': watermark,\n",
        "                    'has_watermark': torch.tensor([0.0], dtype=torch.float32)\n",
        "                }\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data at index {idx}: {e}\")\n",
        "            # Return a different sample in case of error\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "\n",
        "# Modified training function to generate visualizations\n",
        "def optimized_train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.001, visualize=True, output_dir=\"visualizations\"):\n",
        "    \"\"\"Optimized training function for the HiDDeN model with visualization support\"\"\"\n",
        "    if visualize:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        \n",
        "    # Use mixed precision training if CUDA is available\n",
        "    use_amp = torch.cuda.is_available()\n",
        "    scaler = GradScaler() if use_amp else None\n",
        "    \n",
        "    # Use a learning rate scheduler to speed up convergence\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "    \n",
        "    # Loss functions\n",
        "    classifier_criterion = nn.BCELoss()\n",
        "    reconstruction_criterion = nn.MSELoss()\n",
        "    \n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    early_stop_patience = 5  # Stop training if no improvement after this many epochs\n",
        "    \n",
        "    # Lists to track metrics for visualization\n",
        "    epochs = []\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Clear memory before each epoch\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        model.train()\n",
        "        train_total_loss = 0.0\n",
        "        \n",
        "        # Use tqdm for progress bar\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
        "        \n",
        "        for batch in progress_bar:\n",
        "            # Move data to the right device\n",
        "            images = batch['image'].to(device)\n",
        "            watermarks = batch['watermark'].to(device)\n",
        "            has_watermark = batch['has_watermark'].to(device)\n",
        "            \n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Use mixed precision training if available\n",
        "            with autocast() if use_amp else nullcontext():\n",
        "                # Forward pass - classification\n",
        "                watermark_pred = model.classify(images)\n",
        "                classifier_loss = classifier_criterion(watermark_pred, has_watermark)\n",
        "                \n",
        "                # Process based on ground truth\n",
        "                watermarked_indices = has_watermark.squeeze() > 0.5\n",
        "                clean_indices = ~watermarked_indices\n",
        "                \n",
        "                total_loss = classifier_loss\n",
        "                \n",
        "                # Process all images in a single forward pass where possible\n",
        "                if watermarked_indices.sum() > 0:\n",
        "                    watermarked_images = images[watermarked_indices]\n",
        "                    clean_recovered = model.remove_watermark(watermarked_images)\n",
        "                    decoded_watermarks = model.decode(watermarked_images)\n",
        "                    \n",
        "                    # Simplified loss calculation\n",
        "                    removal_loss = 0.1 * torch.mean(torch.abs(\n",
        "                        clean_recovered[:, :, 1:, :] - clean_recovered[:, :, :-1, :]\n",
        "                    ))\n",
        "                    decoder_loss = 0.1 * torch.mean((decoded_watermarks.mean(dim=[2, 3]) - 0.5) ** 2)\n",
        "                    \n",
        "                    total_loss = total_loss + removal_loss + decoder_loss\n",
        "                \n",
        "                if clean_indices.sum() > 0:\n",
        "                    clean_images = images[clean_indices]\n",
        "                    clean_watermarks = watermarks[clean_indices]\n",
        "                    \n",
        "                    encoded_images = model.encode(clean_images, clean_watermarks)\n",
        "                    encoder_loss = reconstruction_criterion(encoded_images, clean_images)\n",
        "                    \n",
        "                    # Simplify this part - combine classification and reconstruction\n",
        "                    decoded_watermarks = model.decode(encoded_images)\n",
        "                    decoder_recovery_loss = reconstruction_criterion(decoded_watermarks, clean_watermarks)\n",
        "                    \n",
        "                    total_loss = total_loss + 0.5 * encoder_loss + 0.5 * decoder_recovery_loss\n",
        "            \n",
        "            # Backward pass and optimize with scaling if using AMP\n",
        "            if use_amp:\n",
        "                scaler.scale(total_loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                total_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            train_total_loss += total_loss.item()\n",
        "            \n",
        "            # Update progress bar\n",
        "            progress_bar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n",
        "        \n",
        "        # Validation with fewer metrics for speed\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_accuracy = 0.0\n",
        "        val_progress_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch in val_progress_bar:\n",
        "                images = batch['image'].to(device)\n",
        "                has_watermark = batch['has_watermark'].to(device)\n",
        "                \n",
        "                watermark_pred = model.classify(images)\n",
        "                batch_val_loss = classifier_criterion(watermark_pred, has_watermark)\n",
        "                val_loss += batch_val_loss.item()\n",
        "                \n",
        "                # Calculate accuracy\n",
        "                predicted = (watermark_pred > 0.5).float()\n",
        "                batch_accuracy = (predicted == has_watermark).float().mean().item()\n",
        "                val_accuracy += batch_accuracy\n",
        "                \n",
        "                # Update progress bar\n",
        "                val_progress_bar.set_postfix({\"val_loss\": f\"{batch_val_loss.item():.4f}\", \"acc\": f\"{batch_accuracy:.4f}\"})\n",
        "        \n",
        "        # Average loss and accuracy\n",
        "        avg_train_loss = train_total_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        avg_val_accuracy = val_accuracy / len(val_loader)\n",
        "        \n",
        "        # Track metrics for visualization\n",
        "        epochs.append(epoch + 1)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        val_accuracies.append(avg_val_accuracy)\n",
        "        \n",
        "        # Update learning rate based on validation loss\n",
        "        scheduler.step(avg_val_loss)\n",
        "        \n",
        "        # Print simple metrics\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f}, \"\n",
        "              f\"Val Loss: {avg_val_loss:.4f}, \"\n",
        "              f\"Val Accuracy: {avg_val_accuracy:.4f}, \"\n",
        "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "        \n",
        "        # Early stopping logic\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "            # Save the best model\n",
        "            torch.save(model.state_dict(), \"watermark_model_best.pth\")\n",
        "            print(f\"New best model saved (val_loss: {best_val_loss:.4f})\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= early_stop_patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                # Load the best model before returning\n",
        "                model.load_state_dict(torch.load(\"watermark_model_best.pth\", map_location=device))\n",
        "                break\n",
        "    \n",
        "    # Create training metrics visualization\n",
        "    if visualize and len(epochs) > 1:\n",
        "        # Create figure with two subplots\n",
        "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
        "        \n",
        "        # Plot losses\n",
        "        ax1.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
        "        ax1.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.set_title('Training and Validation Loss')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "        \n",
        "        # Plot accuracy\n",
        "        ax2.plot(epochs, val_accuracies, 'g-', label='Validation Accuracy')\n",
        "        ax2.set_xlabel('Epochs')\n",
        "        ax2.set_ylabel('Accuracy')\n",
        "        ax2.set_title('Validation Accuracy')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, 'training_metrics.png'), dpi=300)\n",
        "        plt.close()\n",
        "        \n",
        "        print(f\"Training metrics visualization saved to {os.path.join(output_dir, 'training_metrics.png')}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Batch processing for efficient GPU utilization\n",
        "def process_image_batch(batch_files, input_dir, watermark_tensor, output_unwatermarked, output_watermarked, model, quality='medium'):\n",
        "    \"\"\"Process a batch of images at once on GPU\"\"\"\n",
        "    batch_tensors = []\n",
        "    original_sizes = []\n",
        "    filenames = []\n",
        "    \n",
        "    # Collection for visualization\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "    \n",
        "    # Prepare batch - determine processing resolution based on quality\n",
        "    if quality == 'low':\n",
        "        process_size = (64, 64)\n",
        "        resize_method = Image.BILINEAR\n",
        "    elif quality == 'medium':\n",
        "        process_size = (128, 128)\n",
        "        resize_method = Image.BILINEAR\n",
        "    else:  # high\n",
        "        process_size = (256, 256)\n",
        "        resize_method = Image.LANCZOS\n",
        "    \n",
        "    # Create transform based on quality setting\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(process_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "    \n",
        "    # Prepare all valid images in batch\n",
        "    for filename in batch_files:\n",
        "        try:\n",
        "            img_path = os.path.join(input_dir, filename)\n",
        "            image = safe_open_image(img_path)\n",
        "            \n",
        "            if image is None:\n",
        "                continue\n",
        "                \n",
        "            original_sizes.append(image.size)\n",
        "            image_tensor = transform(image).unsqueeze(0)\n",
        "            batch_tensors.append(image_tensor)\n",
        "            filenames.append(filename)\n",
        "            \n",
        "            # Estimate true label from filename (heuristic)\n",
        "            true_has_watermark = 'watermark' in filename.lower()\n",
        "            true_labels.append(1 if true_has_watermark else 0)\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing {filename}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    if not batch_tensors:\n",
        "        return [], true_labels, predicted_labels  # No valid images in this batch\n",
        "    \n",
        "    # Stack tensors into a batch\n",
        "    batch = torch.cat(batch_tensors, dim=0).to(device)\n",
        "    \n",
        "    # Process batch\n",
        "    results = []\n",
        "    with torch.no_grad():\n",
        "        # Classify all at once\n",
        "        probs = model.classify(batch).squeeze()\n",
        "        \n",
        "        # Process each image based on classification\n",
        "        for i, (prob, filename, original_size) in enumerate(zip(probs, filenames, original_sizes)):\n",
        "            try:\n",
        "                image_tensor = batch[i:i+1]\n",
        "                confidence = abs(float(prob) - 0.5) * 2\n",
        "                \n",
        "                # Record prediction for confusion matrix\n",
        "                has_watermark = prob > 0.5\n",
        "                predicted_labels.append(1 if has_watermark else 0)\n",
        "                \n",
        "                # Skip low confidence predictions\n",
        "                if confidence < 0.2:\n",
        "                    results.append(f\"Skipped {filename} (low confidence: {confidence:.2f})\")\n",
        "                    continue\n",
        "                    \n",
        "                if has_watermark:\n",
        "                    # Remove watermark\n",
        "                    cleaned_image = model.remove_watermark(image_tensor)\n",
        "                    cleaned_image = cleaned_image * 0.5 + 0.5  # Denormalize\n",
        "                    cleaned_image_pil = transforms.ToPILImage()(cleaned_image.squeeze(0).cpu())\n",
        "                    cleaned_image_pil = cleaned_image_pil.resize(original_size, resize_method)\n",
        "                    output_path = os.path.join(output_unwatermarked, filename)\n",
        "                    cleaned_image_pil.save(output_path)\n",
        "                    results.append(f\"Removed watermark from: {filename} (confidence: {confidence:.2f})\")\n",
        "                else:\n",
        "                    # Add watermark\n",
        "                    watermarked_image = model.encode(image_tensor, watermark_tensor)\n",
        "                    watermarked_image = watermarked_image * 0.5 + 0.5  # Denormalize\n",
        "                    watermarked_image_pil = transforms.ToPILImage()(watermarked_image.squeeze(0).cpu())\n",
        "                    watermarked_image_pil = watermarked_image_pil.resize(original_size, resize_method)\n",
        "                    output_path = os.path.join(output_watermarked, filename)\n",
        "                    watermarked_image_pil.save(output_path)\n",
        "                    results.append(f\"Added watermark to: {filename} (confidence: {confidence:.2f})\")\n",
        "            except Exception as e:\n",
        "                results.append(f\"Error processing {filename}: {e}\")\n",
        "    \n",
        "    # Clean up GPU memory\n",
        "    del batch\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    return results, true_labels, predicted_labels\n",
        "\n",
        "# Optimized single image processing with quality settings\n",
        "def optimized_process_single_image(filename, input_dir, watermark_img, output_unwatermarked, output_watermarked, model, quality='medium'):\n",
        "    \"\"\"Process a single image with quality settings\"\"\"\n",
        "    \n",
        "    # Determine processing resolution based on quality\n",
        "    if quality == 'low':\n",
        "        process_size = (64, 64)\n",
        "        resize_method = Image.BILINEAR\n",
        "    elif quality == 'medium':\n",
        "        process_size = (128, 128)\n",
        "        resize_method = Image.BILINEAR\n",
        "    else:  # high\n",
        "        process_size = (256, 256)\n",
        "        resize_method = Image.LANCZOS\n",
        "    \n",
        "    img_path = os.path.join(input_dir, filename)\n",
        "\n",
        "    try:\n",
        "        # Load image safely\n",
        "        image = safe_open_image(img_path)\n",
        "        if image is None:\n",
        "            return f\"Error: Could not open {filename}\"\n",
        "            \n",
        "        original_width, original_height = image.size\n",
        "        \n",
        "        # Use quality-based image size for processing\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(process_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ])\n",
        "        \n",
        "        # Pre-scale watermark once\n",
        "        watermark = watermark_img.resize(process_size, Image.BILINEAR)\n",
        "        watermark_tensor = transform(watermark).unsqueeze(0).to(device)\n",
        "        \n",
        "        # Process image\n",
        "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # Classify first - skip processing if confidence is low\n",
        "            watermark_prob = model.classify(image_tensor)\n",
        "            has_watermark = watermark_prob > 0.5\n",
        "            confidence = abs(watermark_prob.item() - 0.5) * 2\n",
        "            \n",
        "            # Only process if confidence is above threshold (avoids processing ambiguous images)\n",
        "            if confidence > 0.2:\n",
        "                if has_watermark.item():\n",
        "                    # Remove watermark\n",
        "                    cleaned_image = model.remove_watermark(image_tensor)\n",
        "                    cleaned_image = cleaned_image * 0.5 + 0.5  # Denormalize\n",
        "                    cleaned_image_pil = transforms.ToPILImage()(cleaned_image.squeeze(0).cpu())\n",
        "                    cleaned_image_pil = cleaned_image_pil.resize((original_width, original_height), resize_method)\n",
        "                    output_path = os.path.join(output_unwatermarked, filename)\n",
        "                    cleaned_image_pil.save(output_path)\n",
        "                    return f\"Removed watermark from: {filename} (confidence: {confidence:.2f})\"\n",
        "                else:\n",
        "                    # Add watermark\n",
        "                    watermarked_image = model.encode(image_tensor, watermark_tensor)\n",
        "                    watermarked_image = watermarked_image * 0.5 + 0.5  # Denormalize\n",
        "                    watermarked_image_pil = transforms.ToPILImage()(watermarked_image.squeeze(0).cpu())\n",
        "                    watermarked_image_pil = watermarked_image_pil.resize((original_width, original_height), resize_method)\n",
        "                    output_path = os.path.join(output_watermarked, filename)\n",
        "                    watermarked_image_pil.save(output_path)\n",
        "                    return f\"Added watermark to: {filename} (confidence: {confidence:.2f})\"\n",
        "            else:\n",
        "                return f\"Skipped {filename} (low confidence: {confidence:.2f})\"\n",
        "    except Exception as e:\n",
        "        return f\"Error processing {filename}: {str(e)}\"\n",
        "\n",
        "# Modified process_in_chunks to track data for confusion matrix\n",
        "def process_in_chunks(image_files, chunk_size=100, **kwargs):\n",
        "    \"\"\"Process large sets of files in manageable chunks\"\"\"\n",
        "    total_processed = 0\n",
        "    all_results = []\n",
        "    all_true_labels = []\n",
        "    all_predicted_labels = []\n",
        "    \n",
        "    for i in range(0, len(image_files), chunk_size):\n",
        "        chunk = image_files[i:i+min(chunk_size, len(image_files)-i)]\n",
        "        print(f\"Processing chunk {i//chunk_size + 1}/{(len(image_files)-1)//chunk_size + 1} ({len(chunk)} files)\")\n",
        "        \n",
        "        # Process this chunk\n",
        "        processed, chunk_true_labels, chunk_pred_labels = optimized_process_images(chunk, **kwargs)\n",
        "        \n",
        "        processed_count = sum(1 for r in processed if not r.startswith(\"Skipped\") and not r.startswith(\"Error\"))\n",
        "        total_processed += processed_count\n",
        "        all_results.extend(processed)\n",
        "        all_true_labels.extend(chunk_true_labels)\n",
        "        all_predicted_labels.extend(chunk_pred_labels)\n",
        "        \n",
        "        # Clear memory between chunks\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        gc.collect()  # Force garbage collection\n",
        "        \n",
        "    return total_processed, all_results, all_true_labels, all_predicted_labels\n",
        "\n",
        "# Modified main image processing function to support visualization\n",
        "def optimized_process_images(image_files, input_dir, watermark_path, output_unwatermarked, output_watermarked, model, quality='medium', force_cpu=False, create_visualizations=True):\n",
        "    \"\"\"Process images with optimal resource usage and collect data for visualizations\"\"\"\n",
        "    os.makedirs(output_unwatermarked, exist_ok=True)\n",
        "    os.makedirs(output_watermarked, exist_ok=True)\n",
        "    \n",
        "    # Collection for visualization\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "    sample_tensors = []  # For correlation heatmap\n",
        "\n",
        "    # Load watermark once\n",
        "    try:\n",
        "        watermark_img = safe_open_image(watermark_path)\n",
        "        if watermark_img is None:\n",
        "            print(f\"Error: Could not load watermark from {watermark_path}\")\n",
        "            return 0, [], true_labels, predicted_labels\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading watermark: {str(e)}\")\n",
        "        return 0, [], true_labels, predicted_labels\n",
        "\n",
        "    # No images to process\n",
        "    if not image_files:\n",
        "        print(f\"No image files found to process\")\n",
        "        return 0, [], true_labels, predicted_labels\n",
        "\n",
        "    # Determine processing mode based on available resources\n",
        "    use_gpu_batch = torch.cuda.is_available() and not force_cpu\n",
        "    \n",
        "    results = []\n",
        "    if use_gpu_batch:\n",
        "        # Prepare watermark tensor once for batched processing\n",
        "        # Determine resolution based on quality setting\n",
        "        if quality == 'low':\n",
        "            process_size = (64, 64)\n",
        "        elif quality == 'medium':\n",
        "            process_size = (128, 128)\n",
        "        else:  # high\n",
        "            process_size = (256, 256)\n",
        "            \n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(process_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ])\n",
        "        \n",
        "        watermark = watermark_img.resize(process_size, Image.BILINEAR)\n",
        "        watermark_tensor = transform(watermark).unsqueeze(0).to(device)\n",
        "        \n",
        "        # Calculate optimal batch size based on available GPU memory\n",
        "        available_memory = torch.cuda.get_device_properties(0).total_memory\n",
        "        free_memory = available_memory - torch.cuda.memory_allocated()\n",
        "        \n",
        "        # Estimate memory per image based on resolution\n",
        "        if quality == 'low':\n",
        "            memory_per_image = 6 * 1024 * 1024  # ~6MB per image\n",
        "        elif quality == 'medium':\n",
        "            memory_per_image = 24 * 1024 * 1024  # ~24MB per image\n",
        "        else:\n",
        "            memory_per_image = 96 * 1024 * 1024  # ~96MB per image\n",
        "            \n",
        "        # Reserve 20% of memory for overhead\n",
        "        safe_memory = free_memory * 0.8\n",
        "        batch_size = min(max(1, int(safe_memory // memory_per_image)), 32)  # Cap at 32\n",
        "        \n",
        "        print(f\"Processing with GPU batches of size {batch_size}, quality={quality}\")\n",
        "        \n",
        "        # Process in batches\n",
        "        for i in range(0, len(image_files), batch_size):\n",
        "            batch_files = image_files[i:i+min(batch_size, len(image_files)-i)]\n",
        "            print(f\"Processing batch {i//batch_size + 1}/{(len(image_files)-1)//batch_size + 1} ({len(batch_files)} files)\")\n",
        "            \n",
        "            batch_results, batch_true_labels, batch_pred_labels = process_image_batch(\n",
        "                batch_files,\n",
        "                input_dir,\n",
        "                watermark_tensor,\n",
        "                output_unwatermarked,\n",
        "                output_watermarked,\n",
        "                model,\n",
        "                quality\n",
        "            )\n",
        "            \n",
        "            results.extend(batch_results)\n",
        "            true_labels.extend(batch_true_labels)\n",
        "            predicted_labels.extend(batch_pred_labels)\n",
        "            \n",
        "            # Collect sample tensors for correlation heatmap (limit to avoid memory issues)\n",
        "            if create_visualizations and len(sample_tensors) < 100:\n",
        "                for filename in batch_files[:min(5, len(batch_files))]:  # Take at most 5 from each batch\n",
        "                    try:\n",
        "                        img_path = os.path.join(input_dir, filename)\n",
        "                        image = safe_open_image(img_path)\n",
        "                        if image is not None:\n",
        "                            image_tensor = transform(image).unsqueeze(0)\n",
        "                            sample_tensors.append(image_tensor)\n",
        "                    except Exception:\n",
        "                        continue\n",
        "            \n",
        "            # Clean up memory after each batch\n",
        "            torch.cuda.empty_cache()\n",
        "    else:\n",
        "        # Fall back to parallel CPU processing\n",
        "        num_workers = min(os.cpu_count() or 1, 4)  # Cap at 4 workers\n",
        "        print(f\"Processing with CPU using {num_workers} workers, quality={quality}\")\n",
        "        \n",
        "        # Modified to collect true/predicted labels\n",
        "        for filename in tqdm(image_files, desc=\"Processing images\"):\n",
        "            # Estimate true label from filename (heuristic)\n",
        "            true_has_watermark = 'watermark' in filename.lower()\n",
        "            true_labels.append(1 if true_has_watermark else 0)\n",
        "            \n",
        "            # Process image\n",
        "            result = optimized_process_single_image(\n",
        "                filename, \n",
        "                input_dir=input_dir,\n",
        "                watermark_img=watermark_img,\n",
        "                output_unwatermarked=output_unwatermarked,\n",
        "                output_watermarked=output_watermarked,\n",
        "                model=model,\n",
        "                quality=quality\n",
        "            )\n",
        "            \n",
        "            # Determine predicted label based on result\n",
        "            if \"Added watermark\" in result:\n",
        "                predicted_labels.append(0)  # Predicted clean, added watermark\n",
        "            elif \"Removed watermark\" in result:\n",
        "                predicted_labels.append(1)  # Predicted watermarked, removed watermark\n",
        "            elif \"Skipped\" in result:\n",
        "                # For skipped images, use a heuristic based on the confidence\n",
        "                confidence_str = result.split(\"confidence: \")[1].split(\")\")[0]\n",
        "                confidence = float(confidence_str)\n",
        "                predicted_labels.append(1 if confidence > 0.5 else 0)\n",
        "            else:\n",
        "                # Error case\n",
        "                predicted_labels.append(1 if true_has_watermark else 0)  # Default to true label\n",
        "            \n",
        "            results.append(result)\n",
        "            \n",
        "            # Collect sample tensors for correlation heatmap (limit to avoid memory issues)\n",
        "            if create_visualizations and len(sample_tensors) < 50:\n",
        "                try:\n",
        "                    img_path = os.path.join(input_dir, filename)\n",
        "                    image = safe_open_image(img_path)\n",
        "                    if image is not None:\n",
        "                        image_tensor = transform(image).unsqueeze(0)\n",
        "                        sample_tensors.append(image_tensor)\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "    # Create visualizations if requested\n",
        "    if create_visualizations and len(true_labels) > 0 and len(predicted_labels) > 0:\n",
        "        # Create confusion matrix\n",
        "        create_confusion_matrix(true_labels, predicted_labels)\n",
        "        \n",
        "        # Create correlation heatmap if we have enough samples\n",
        "        if len(sample_tensors) > 10:\n",
        "            # Only use a subset to avoid memory issues\n",
        "            sample_tensors = sample_tensors[:min(50, len(sample_tensors))]\n",
        "            sample_batch = torch.cat(sample_tensors, dim=0).to(device)\n",
        "            create_correlation_heatmap(model, sample_batch)\n",
        "\n",
        "    # Count processed images\n",
        "    processed_count = sum(1 for result in results if not result.startswith(\"Skipped\") and not result.startswith(\"Error\"))\n",
        "    \n",
        "    return processed_count, results, true_labels, predicted_labels\n",
        "\n",
        "# Context manager for null context when not using autocast\n",
        "class nullcontext:\n",
        "    def __enter__(self): return self\n",
        "    def __exit__(self, *args): pass\n",
        "\n",
        "# Main function with error handling and user options\n",
        "def optimized_main():\n",
        "    try:\n",
        "        # Create visualizations directory\n",
        "        os.makedirs(\"visualizations\", exist_ok=True)\n",
        "        \n",
        "        # Define data directories\n",
        "        train_clean_dir = \"wm-nowm/train/no-watermark\"\n",
        "        train_watermarked_dir = \"wm-nowm/train/watermark\"\n",
        "        val_clean_dir = \"wm-nowm/valid/no-watermark\"\n",
        "        val_watermarked_dir = \"wm-nowm/valid/watermark\" \n",
        "        \n",
        "        # Check if directories exist\n",
        "        for directory in [train_clean_dir, train_watermarked_dir, val_clean_dir, val_watermarked_dir]:\n",
        "            if not os.path.exists(directory):\n",
        "                print(f\"Warning: Directory {directory} does not exist.\")\n",
        "        \n",
        "        # Allow user to choose whether to train or just process images\n",
        "        mode = input(\"Choose mode (1: Train + Process, 2: Process only): \").strip()\n",
        "        \n",
        "        if mode == \"2\":\n",
        "            print(\"Processing mode only - will load existing model if available.\")\n",
        "            should_train = False\n",
        "        else:\n",
        "            print(\"Training + Processing mode selected.\")\n",
        "            should_train = True\n",
        "            \n",
        "        # Ask about quality settings\n",
        "        quality_choice = input(\"Choose processing quality (1: Low, 2: Medium, 3: High): \").strip()\n",
        "        if quality_choice == \"1\":\n",
        "            quality = \"low\"\n",
        "            print(\"Using low quality (faster but less accurate).\")\n",
        "        elif quality_choice == \"3\":\n",
        "            quality = \"high\"\n",
        "            print(\"Using high quality (slower but more accurate).\")\n",
        "        else:\n",
        "            quality = \"medium\"\n",
        "            print(\"Using medium quality (balanced).\")\n",
        "        \n",
        "        # Model parameters based on quality\n",
        "        if quality == \"low\":\n",
        "            process_size = (64, 64)\n",
        "        elif quality == \"medium\":\n",
        "            process_size = (128, 128)\n",
        "        else:  # high\n",
        "            process_size = (256, 256)\n",
        "            \n",
        "        # Get watermark path from user for training\n",
        "        if should_train:\n",
        "            watermark_path = input(\"Enter path to watermark image for training (or press Enter to use a blank watermark): \")\n",
        "            if not watermark_path or not os.path.exists(watermark_path):\n",
        "                print(\"No valid watermark path provided. Will use a blank watermark during training.\")\n",
        "                watermark_path = None\n",
        "        \n",
        "            # Optimized transforms with appropriate image size\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize(process_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "            ])\n",
        "            \n",
        "            # Create datasets\n",
        "            train_dataset = WatermarkDataset(\n",
        "                clean_dir=train_clean_dir,\n",
        "                watermarked_dir=train_watermarked_dir,\n",
        "                watermark_path=watermark_path,\n",
        "                transform=transform,\n",
        "                is_train=True\n",
        "            )\n",
        "            \n",
        "            val_dataset = WatermarkDataset(\n",
        "                clean_dir=val_clean_dir, \n",
        "                watermarked_dir=val_watermarked_dir,\n",
        "                watermark_path=watermark_path,\n",
        "                transform=transform,\n",
        "                is_train=False\n",
        "            )\n",
        "            \n",
        "            # Create visualizations for dataset distributions\n",
        "            visualize_dataset_distribution(train_dataset, val_dataset)\n",
        "            \n",
        "            # Optimize batch size based on system resources and quality\n",
        "            gpu_available = torch.cuda.is_available() or torch.backends.mps.is_available()\n",
        "            \n",
        "            if quality == \"low\":\n",
        "                batch_size = 64 if gpu_available else 32\n",
        "            elif quality == \"medium\":\n",
        "                batch_size = 32 if gpu_available else 16\n",
        "            else:  # high\n",
        "                batch_size = 16 if gpu_available else 8\n",
        "            \n",
        "            # Use only 1 worker for DataLoader to avoid broken pipe errors\n",
        "            num_workers_dl = 0\n",
        "            \n",
        "            # Use pin_memory for faster data transfer to GPU\n",
        "            pin_memory = gpu_available\n",
        "            \n",
        "            train_loader = DataLoader(\n",
        "                train_dataset, \n",
        "                batch_size=batch_size, \n",
        "                shuffle=True, \n",
        "                num_workers=num_workers_dl,\n",
        "                pin_memory=pin_memory,\n",
        "                persistent_workers=False\n",
        "            )\n",
        "            \n",
        "            val_loader = DataLoader(\n",
        "                val_dataset, \n",
        "                batch_size=batch_size, \n",
        "                shuffle=False, \n",
        "                num_workers=num_workers_dl,\n",
        "                pin_memory=pin_memory,\n",
        "                persistent_workers=False\n",
        "            )\n",
        "        \n",
        "        # Create or load model\n",
        "        watermark_strength = 0.5 if quality == \"low\" else 0.8\n",
        "        model = OptimizedHiDDeNModel(watermark_strength=watermark_strength)\n",
        "        \n",
        "        # Path for saved model\n",
        "        model_path = \"watermark_model.pth\"\n",
        "        best_model_path = \"watermark_model_best.pth\"\n",
        "        \n",
        "        # Check for existing model files\n",
        "        if os.path.exists(best_model_path):\n",
        "            print(f\"Loading best model from {best_model_path}\")\n",
        "            model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "        elif os.path.exists(model_path):\n",
        "            print(f\"Loading model from {model_path}\")\n",
        "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "        elif not should_train:\n",
        "            print(\"No model file found. Please run training first or choose an existing model.\")\n",
        "            return\n",
        "            \n",
        "        # Train model if requested\n",
        "        if should_train:\n",
        "            print(\"Training model...\")\n",
        "            try:\n",
        "                # Enable cuDNN benchmarking for faster training if available\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.backends.cudnn.benchmark = True\n",
        "                \n",
        "                model = optimized_train_model(\n",
        "                    model=model,\n",
        "                    train_loader=train_loader,\n",
        "                    val_loader=val_loader,\n",
        "                    num_epochs=10,\n",
        "                    learning_rate=0.001,\n",
        "                    visualize=True  # Enable training visualization\n",
        "                )\n",
        "                \n",
        "                # Save the final model\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print(f\"Model saved to {model_path}\")\n",
        "                \n",
        "                # Disable benchmarking for inference\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.backends.cudnn.benchmark = False\n",
        "            except Exception as e:\n",
        "                print(f\"Error during training: {e}\")\n",
        "                # If best model exists, load it\n",
        "                if os.path.exists(best_model_path):\n",
        "                    print(f\"Loading last best model from {best_model_path}\")\n",
        "                    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "                else:\n",
        "                    print(\"Training failed and no best model found. Exiting.\")\n",
        "                    return\n",
        "                \n",
        "        # Process user-provided images\n",
        "        print(\"\\n--- Watermark Processing ---\")\n",
        "        input_dir = input(\"Enter the directory path containing images to process: \")\n",
        "        \n",
        "        if not input_dir or not os.path.exists(input_dir):\n",
        "            print(\"Error: Invalid input directory.\")\n",
        "            return\n",
        "        \n",
        "        watermark_path = input(\"Enter the path to the watermark image you want to apply: \")\n",
        "        if not watermark_path or not os.path.exists(watermark_path):\n",
        "            print(\"Error: Invalid watermark path.\")\n",
        "            return\n",
        "        \n",
        "        output_unwatermarked = \"output/unwatermarked\"\n",
        "        output_watermarked = \"output/watermarked\"\n",
        "        \n",
        "        # Get list of image files\n",
        "        image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp'))]\n",
        "        \n",
        "        if len(image_files) == 0:\n",
        "            print(f\"No image files found in {input_dir}\")\n",
        "            return\n",
        "            \n",
        "        # Ask about chunk processing for large datasets\n",
        "        if len(image_files) > 100:\n",
        "            chunked = input(f\"Found {len(image_files)} images. Process in chunks? (y/n): \").strip().lower()\n",
        "            if chunked == 'y':\n",
        "                print(\"Processing in chunks to manage memory...\")\n",
        "                chunk_size = 50  # Choose a reasonable chunk size\n",
        "                total_processed, results, true_labels, pred_labels = process_in_chunks(\n",
        "                    image_files, \n",
        "                    chunk_size=chunk_size,\n",
        "                    input_dir=input_dir,\n",
        "                    watermark_path=watermark_path,\n",
        "                    output_unwatermarked=output_unwatermarked,\n",
        "                    output_watermarked=output_watermarked,\n",
        "                    model=model,\n",
        "                    quality=quality,\n",
        "                    create_visualizations=True\n",
        "                )\n",
        "            else:\n",
        "                # Process all at once\n",
        "                print(f\"Processing all {len(image_files)} images at once...\")\n",
        "                total_processed, results, true_labels, pred_labels = optimized_process_images(\n",
        "                    image_files,\n",
        "                    input_dir=input_dir,\n",
        "                    watermark_path=watermark_path,\n",
        "                    output_unwatermarked=output_unwatermarked,\n",
        "                    output_watermarked=output_watermarked,\n",
        "                    model=model,\n",
        "                    quality=quality,\n",
        "                    create_visualizations=True\n",
        "                )\n",
        "        else:\n",
        "            # Process all at once for smaller datasets\n",
        "            print(f\"Processing {len(image_files)} images...\")\n",
        "            total_processed, results, true_labels, pred_labels = optimized_process_images(\n",
        "                image_files,\n",
        "                input_dir=input_dir,\n",
        "                watermark_path=watermark_path,\n",
        "                output_unwatermarked=output_unwatermarked,\n",
        "                output_watermarked=output_watermarked,\n",
        "                model=model,\n",
        "                quality=quality,\n",
        "                create_visualizations=True\n",
        "            )\n",
        "        \n",
        "        # Create confusion matrix if we have enough data\n",
        "        if len(true_labels) > 0 and len(pred_labels) > 0:\n",
        "            create_confusion_matrix(true_labels, pred_labels)\n",
        "        \n",
        "        # Print summary results\n",
        "        skipped = sum(1 for r in results if r.startswith(\"Skipped\"))\n",
        "        errors = sum(1 for r in results if r.startswith(\"Error\"))\n",
        "        watermarked = sum(1 for r in results if \"Added watermark\" in r)\n",
        "        unwatermarked = sum(1 for r in results if \"Removed watermark\" in r)\n",
        "        \n",
        "        print(\"\\n----- Processing Summary -----\")\n",
        "        print(f\"Total images: {len(image_files)}\")\n",
        "        print(f\"Successfully processed: {total_processed}\")\n",
        "        print(f\"  - Watermarked: {watermarked}\")\n",
        "        print(f\"  - Unwatermarked: {unwatermarked}\")\n",
        "        print(f\"Skipped (low confidence): {skipped}\")\n",
        "        print(f\"Errors: {errors}\")\n",
        "        print(f\"Unwatermarked images saved to: {output_unwatermarked}\")\n",
        "        print(f\"Watermarked images saved to: {output_watermarked}\")\n",
        "        print(f\"Visualizations saved to: visualizations/\")\n",
        "        \n",
        "        # Ask if user wants to see detailed results\n",
        "        if input(\"Show detailed results? (y/n): \").strip().lower() == 'y':\n",
        "            for result in results:\n",
        "                print(result)\n",
        "    \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation cancelled by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Main entry point\n",
        "if __name__ == \"__main__\":\n",
        "    optimized_main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
